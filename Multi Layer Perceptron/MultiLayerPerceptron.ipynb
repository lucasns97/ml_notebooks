{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP.ipynb","provenance":[],"collapsed_sections":["dypO8NO1vcjO","yzb002xew6m-","Z0amOfaScqyA","CG3q9s-gsqct","Ohg2D7-AziyD","YsAZVWEi0UIS","rObKQKlk1BF8","IFDTxEJZ17zv","LUb3EbWy2lyY"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ba1fa9f3e0534780a9accd2bb1a5f4e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_925f7358e08840fda19c817875a80915","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_735578905c9942398bc3cb0de39b9bab","IPY_MODEL_e40ef7b61e404cf0b855e393d0bd733a","IPY_MODEL_0c91b06b1f3b404f80dab5cc6e97d9d2"]}},"925f7358e08840fda19c817875a80915":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"735578905c9942398bc3cb0de39b9bab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ecc2a5eb5fc44b5b214a314bf831091","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 239/2000:  12%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2fbf8ac369d84aa59717a68446c7ed80"}},"e40ef7b61e404cf0b855e393d0bd733a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b8f8f02853b24afc9a53fe3307b815fb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":2000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":238,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57385cf7acb446c5af5f4e193729a81f"}},"0c91b06b1f3b404f80dab5cc6e97d9d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_769b27f8320d46fa908e6b56a6edca67","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 238/2000 [00:02&lt;00:16, 108.07it/s, loss=0.000993]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6358ccb6eff74e4b8e4e720b62515395"}},"0ecc2a5eb5fc44b5b214a314bf831091":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2fbf8ac369d84aa59717a68446c7ed80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8f8f02853b24afc9a53fe3307b815fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"57385cf7acb446c5af5f4e193729a81f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"769b27f8320d46fa908e6b56a6edca67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6358ccb6eff74e4b8e4e720b62515395":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a6b8f7f21a6c463683a68a562619b855":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e23be2aa71e14bf6b40c32aea769a838","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d7b31b440cf34c9aa9f6c268eeb6fe92","IPY_MODEL_f25750b7f46b4164b1a36eddc8af1a86","IPY_MODEL_e773f9e9f9ee4792b590ca2eccf15f9f"]}},"e23be2aa71e14bf6b40c32aea769a838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7b31b440cf34c9aa9f6c268eeb6fe92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7a20900bca96427aad7bce551cdf0077","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 4000/4000: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad106899b9b8484eb73d8923d87b1209"}},"f25750b7f46b4164b1a36eddc8af1a86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3876d31e048b4c60b0d7f3ef8f038fb6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1de47dc0b0a8421ebf7ee33e9367e534"}},"e773f9e9f9ee4792b590ca2eccf15f9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b17ab1364a4741a19a60c533f2986c4d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4000/4000 [00:53&lt;00:00, 80.30it/s, loss=0.0297]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ef037d1171d420caad9613b899e4771"}},"7a20900bca96427aad7bce551cdf0077":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ad106899b9b8484eb73d8923d87b1209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3876d31e048b4c60b0d7f3ef8f038fb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1de47dc0b0a8421ebf7ee33e9367e534":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b17ab1364a4741a19a60c533f2986c4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7ef037d1171d420caad9613b899e4771":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e7d61a05b6fd48e9b9c0d3745204e865":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5ada9cd4e58e477380be9664197af95a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f56790f770fa4eecab0097b8d4e918d4","IPY_MODEL_a88167b4a2704354b0db1c4c36e85053","IPY_MODEL_befb2fdc1b0747d68cb80cdd2860ce6b"]}},"5ada9cd4e58e477380be9664197af95a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f56790f770fa4eecab0097b8d4e918d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3af60b82effa422eb69a9021a5b9d2fb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 143/4000:   4%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d6903a799824ee88292a936df6e59ba"}},"a88167b4a2704354b0db1c4c36e85053":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_38509af77ce040b49110a4a3c449386d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":4000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":142,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb1116aadeb9472bba02ca2846578370"}},"befb2fdc1b0747d68cb80cdd2860ce6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5b2f7807d32940c0ad70546b7ecc4962","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 142/4000 [00:03&lt;01:24, 45.90it/s, loss=0.000964]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64747822e92149db8f46b619b0a6a333"}},"3af60b82effa422eb69a9021a5b9d2fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7d6903a799824ee88292a936df6e59ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38509af77ce040b49110a4a3c449386d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"eb1116aadeb9472bba02ca2846578370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5b2f7807d32940c0ad70546b7ecc4962":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"64747822e92149db8f46b619b0a6a333":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"8yF82hapsX1s"},"source":["# Grupo 3 - Multi Layer Perceptron Modeling (Exercício 2)\n","\n","---------------------------------------------\n","\n","### Participants:\n"," - Francielle Vargas - 9527629\n"," - Lucas Nunes Sequeira - 9009642\n"," - Emanuel Huber - 12110113\n","\n","#### Date: 26/08/2021\n","\n","---------------------------------------------\n","\n","#### Descrição e Instrução\n","\n","Este notebook foi feito para a disciplina SCC5809 - Redes Neurais\n","\n","No notebook contém\n","\n","1. A implementação da classe **Perceptron**\n","2. A implementação da classe **PerceptronLayer**\n","3. A implementação da classe **MLP**\n","4. Resolução do problema XOR\n","5. Resolução do problema de Auto-Encoder\n","\n","Para utilizá-lo, basta executar todas as células deste notebook.\n","\n","_link de acesso ao colab: https://colab.research.google.com/drive/1W8kvzb0tthCJdDXfPy23U-oy7umToISG?usp=sharing_"]},{"cell_type":"markdown","metadata":{"id":"dypO8NO1vcjO"},"source":["### Libs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYNxDhZBG8rj","executionInfo":{"status":"ok","timestamp":1630506607532,"user_tz":180,"elapsed":19815,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"eadac08c-8563-474f-a429-d3621c009f06"},"source":["# Install Libs\n","!pip install numpy==1.19.5\n","!pip install tqdm==4.62.0\n","!pip install plotly==4.4.1\n","!pip install pandas==1.1.5"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: tqdm==4.62.0 in /usr/local/lib/python3.7/dist-packages (4.62.0)\n","Requirement already satisfied: plotly==4.4.1 in /usr/local/lib/python3.7/dist-packages (4.4.1)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly==4.4.1) (1.3.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly==4.4.1) (1.15.0)\n","Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.5) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"id":"MZu5FYUFvd-0","executionInfo":{"status":"ok","timestamp":1630506607791,"user_tz":180,"elapsed":269,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["# Math lib\n","import numpy as np\n","\n","# Log lib\n","from tqdm.auto import tqdm\n","\n","# Visualization Lib\n","import plotly.express as px\n","\n","# Copy for deepcopy\n","import copy\n","\n","# Pandas for visualization\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yzb002xew6m-"},"source":["### Activation function"]},{"cell_type":"code","metadata":{"id":"gjexUbwHw5u3","executionInfo":{"status":"ok","timestamp":1630506607792,"user_tz":180,"elapsed":20,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["class Sigmoid(object):\n","  '''\n","  Sigmoid Activation Function\n","  \n","    f(x) =  1 / (1 + e^(-x))\n","  '''\n","\n","  def __init__(self):\n","\n","    # Last call data\n","    self.last_grad = 0\n","    self.last_input = 0\n","    self.last_output = 0\n","\n","  def _update_last_call(self, x, y, grad = True):\n","    '''Update last call data'''\n","\n","    # Gradient\n","    if grad:\n","      self.last_grad = self.gradient(x)\n","\n","    # Update last input and output\n","    self.last_input = x\n","    self.last_output = y\n","\n","  def __call__(self, x):\n","    '''Calculate sigmoid function of x'''\n","\n","    if isinstance(x, list):\n","      x = np.array(x)\n","\n","    return 1 / (1 + np.exp(-x))\n","\n","  def calculate(self, x, grad: bool = True):\n","    '''Calculate sigmoid function of x'''\n","\n","    # Calculation\n","    y = self(x)\n","\n","    # Update last call data\n","    self._update_last_call(x, y, grad)\n","\n","    return y\n","\n","  def copy(self):\n","    return Sigmoid()\n","\n","  def gradient(self, x):\n","    '''Calculate sigmoid gradient within x'''\n","\n","    return self(x)*(1 - self(x))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"MCUDAXp8Wfwg","executionInfo":{"status":"ok","timestamp":1630506607793,"user_tz":180,"elapsed":19,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["class Swish(object):\n","  '''\n","  Swish Activation Function\n","  \n","    f(x) =  x * sigmoid(x)\n","  '''\n","\n","  def __init__(self):\n","\n","    self.sigmoid = Sigmoid()\n","\n","    # Last call data\n","    self.last_grad = 0\n","    self.last_input = 0\n","    self.last_output = 0\n","\n","  def _update_last_call(self, x, y, grad = True):\n","    '''Update last call data'''\n","\n","    # Gradient\n","    if grad:\n","      self.last_grad = self.gradient(x)\n","\n","    # Update last input and output\n","    self.last_input = x\n","    self.last_output = y\n","\n","  def __call__(self, x):\n","    '''Calculate swish function of x'''\n","\n","    if isinstance(x, list):\n","      x = np.array(x)\n","\n","    return x*self.sigmoid(x)\n","\n","  def calculate(self, x, grad: bool = True):\n","    '''Calculate swish function of x'''\n","\n","    # Calculation\n","    y = self(x)\n","\n","    # Update last call data\n","    self._update_last_call(x, y, grad)\n","    \n","    return y\n","\n","  def copy(self):\n","    return Swish()\n","\n","  def gradient(self, x):\n","    '''Calculate swish gradient within x'''\n","\n","    return self.sigmoid(x)*(1 + x*(1 - self.sigmoid(x)))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"zZgNtLEEYMUI","executionInfo":{"status":"ok","timestamp":1630506607794,"user_tz":180,"elapsed":17,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["class Relu(object):\n","  '''\n","  Relu Activation Function\n","  \n","    f(x) =  \n","      0 if x < 0\n","      x if x >= 0\n","  '''\n","\n","  def __init__(self):\n","\n","    # Last call data\n","    self.last_grad = 0\n","    self.last_input = 0\n","    self.last_output = 0\n","\n","  def _update_last_call(self, x, y, grad = True):\n","    '''Update last call data'''\n","\n","    # Gradient\n","    if grad:\n","      self.last_grad = self.gradient(x)\n","\n","    # Update last input and output\n","    self.last_input = x\n","    self.last_output = y\n","\n","  def __call__(self, x):\n","    '''Calculate relu function of x'''\n","\n","    return np.where(x < 0, 0.0, x)\n","\n","  def calculate(self, x, grad: bool = True):\n","    '''Calculate relu function of x'''\n","\n","    # Calculation\n","    y = self(x)\n","\n","    # Update last call data\n","    self._update_last_call(x, y, grad)\n","    \n","    return y\n","\n","  def copy(self):\n","    return Relu()\n","\n","  def gradient(self, x):\n","    '''Calculate relu gradient within x'''\n","\n","    return np.where(x < 0, 0.0, 1)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z0amOfaScqyA"},"source":["### Loss Function"]},{"cell_type":"code","metadata":{"id":"_ojfZWi4cscX","executionInfo":{"status":"ok","timestamp":1630506608035,"user_tz":180,"elapsed":255,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["class MSE(object):\n","  '''\n","  Mean Squared Error Loss Function\n","  \n","    f(x) =  1/(2*m) * sum((ref_y - hyp_y)**2)\n","  '''\n","\n","  def __init__(self):\n","    \n","    # Last call data\n","    self.last_grad = 0\n","    self.last_input = 0\n","    self.last_output = 0\n","\n","  def _update_last_call(self, x, y, grad = True):\n","    '''Update last call data'''\n","\n","    # Gradient\n","    if grad:\n","      self.last_grad = self.gradient(x[0], x[1])\n","\n","    # Update last input and output\n","    self.last_input = x\n","    self.last_output = y\n","\n","  def __call__(self, ref: np.ndarray, hyp: np.ndarray):\n","    '''Calculate mean squared error between ref and hyp'''\n","\n","    if isinstance(ref, list):\n","      ref = np.array(ref)\n","    if isinstance(hyp, list):\n","      hyp = np.array(hyp)\n","\n","    size = len(ref)\n","\n","    # Quadratic Error Sum\n","    quadratic_sum = np.sum((ref - hyp)**2)\n","\n","    return quadratic_sum/(2*size)\n","\n","  def calculate(self, ref: np.ndarray, hyp: np.ndarray, grad: bool = True):\n","    '''Calculate mean squared error between ref and hyp'''\n","\n","    # Calculation\n","    y = self(ref, hyp)\n","\n","    # Update last call data\n","    self._update_last_call((ref, hyp), y, grad)\n","\n","    return y\n","\n","  def copy(self):\n","    return MSE()\n","\n","  def gradient(self, ref: np.ndarray, hyp: np.ndarray):\n","    '''Calculate MSE gradient within hyp'''\n","\n","    size = len(ref)\n","\n","    return -np.sum(ref - hyp)/size"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CG3q9s-gsqct"},"source":["### Perceptron Class"]},{"cell_type":"code","metadata":{"id":"H8icU1F4ssXA","executionInfo":{"status":"ok","timestamp":1630506608038,"user_tz":180,"elapsed":5,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["class Perceptron():\n","\n","  def __init__(self, input_size: int = 2, init_rule: str = 'zero', activation = None):\n","    '''Initializes Perceptron\n","    \n","      Params:\n","        input_size (int): size of input data\n","        init_rule (str): initialization parameter to set initial weight values\n","        activation (func): function to apply activation step\n","      '''\n","\n","    # Perceptron size\n","    self.input_size = input_size\n","    self.size = input_size + 1\n","\n","    # Initialize weights\n","    self.init_weights(init_rule)\n","\n","    # Activation function\n","    if activation is None:\n","      activation = Sigmoid()\n","    self.activation = activation.copy()\n","\n","    # Health check\n","    self._health_check()\n","  \n","  def _health_check(self):\n","    '''Perform a health check prediction'''\n","\n","    # 1D (input_size)\n","    X = np.random.rand(self.input_size)\n","    self(X)\n","\n","    # 2D (4 items, input_size)\n","    X = np.random.rand(4, self.input_size)\n","    self(X)\n","\n","  def init_weights(self, init_rule: str = 'zero'):\n","    '''Initialize weights\n","    \n","      Params:\n","        init_rule (str): initialization parameter to set initial weight values\n","    '''\n","\n","    # Assure initializarion rule\n","    assert init_rule in ['zero', 'rand'], \"'init_rule' must be zero or rand\"\n","\n","    if init_rule == 'zero':\n","      # Zero values\n","      self.weights = np.zeros(self.size)\n","    \n","    elif init_rule == 'rand':\n","      # Random values in [-0.1, 0,1]\n","      self.weights = np.random.rand(self.size) - 0.5\n","      self.weights /= 0.5\n","\n","  def set_weights(self, weights: np.ndarray):\n","    '''Update weights\n","\n","      Params:\n","        weights (np.ndarray): array of weights\n","    '''\n","\n","    # Assure perceptron size equals given weights size\n","    assert self.size == len(weights), f\"Perceptron size ({self.size}) != weights size ({len(weights)})\"\n","\n","    # Update weights\n","    self.weights = weights.copy()\n","\n","  def get_weights(self) -> np.ndarray:\n","    '''Return a copy of current weights'''\n","\n","    # Return weights\n","    return self.weights.copy()\n","\n","  def _add_bias_term(self, X: np.ndarray, value = 1.0, is_batch = True) -> np.ndarray:\n","    '''Add bias term to X values, ie:\n","       Given (x_i) in = [1, 0] -> out: [value, 1, 0]\n","\n","      Params:\n","        X (np.ndarray): Batch of items (2D array) or a item (1D array)\n","        value (float): Bias factor value. Default = 1.0\n","        is_batch (bool): Boolean to explicity that is or not a batch of items\n","\n","      Returns:\n","        X (np.ndarray) with the bias term concatenated, eg:\n","    '''\n","\n","    if is_batch:\n","      # Get batch_size\n","      batch_size = X.shape[0]\n","\n","      # Add bias term\n","      X = np.concatenate([value*np.ones((batch_size, 1)), X], axis=1)\n","    \n","    else:\n","      # Add bias term\n","      X = np.concatenate([[value], X])\n","\n","    return X\n","\n","  def _prepare_input(self, X: np.ndarray) -> np.ndarray:\n","    '''Prepare input X\n","       \n","       1. Add batch dimension (if applies)\n","       2. Add bias term\n","\n","      Params:\n","        X (np.ndarray): Batch of items (2D array) or a item (1D array)\n","    '''\n","\n","    # Make sure is a np.ndarray\n","    X = np.array(X)\n","\n","    # Verify if it is sigle item and batch it\n","    if len(X.shape) == 1:\n","      # Add batch dimension\n","      X = np.expand_dims(X, 0)\n","\n","    # Add bias term\n","    X = self._add_bias_term(X)\n","\n","    return X\n","\n","\n","  def forward(self, X: np.ndarray) -> np.ndarray:\n","    '''Make a batch or single prediction\n","    \n","      Params:\n","        X (np.ndarray): Batch of items (2D array) or a item (1D array)\n","        \n","      Returns:\n","        output (np.ndarray) logits\n","    '''\n","    \n","    # Prepare input data\n","    X = self._prepare_input(X)\n","\n","    # Inner product of inputs and weigths (net)\n","    net = self.weights * X # multiplication\n","    net = np.sum(net, axis = 1) # sum reduction\n","\n","    # Apply activation\n","    output = self.activation.calculate(net)\n","\n","    return output\n","\n","  def __call__(self, X: np.ndarray) -> np.ndarray:\n","    '''Make a batch or single prediction (runs forward method)\n","    \n","      Params:\n","        X (np.ndarray): Batch of items (2D array) or a item (1D array)\n","        \n","      Returns:\n","        output (np.ndarray) logits\n","    '''\n","\n","    return self.forward(X)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ohg2D7-AziyD"},"source":["### Perceptron Layer Class"]},{"cell_type":"code","metadata":{"id":"mYBuCiG_zkhr","executionInfo":{"status":"ok","timestamp":1630506608265,"user_tz":180,"elapsed":232,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["class PerceptronLayer():\n","\n","  def __init__(self, input_size: int = 2, units: int = 2, init_rule: str = 'zero',\n","               activation = None):\n","    '''Initializes Perceptron Layer\n","    \n","      Params:\n","        input_size (int): size of input data\n","        units (int): perceptron units to use in layer\n","        init_rule (str): initialization parameter to set initial weight values\n","        activation (func): function to apply activation step\n","      '''\n","\n","    # Perceptron Layer sizes\n","    self.input_size = input_size\n","    self.size = input_size + 1\n","    self.num_units = units\n","    self.output_size = self.num_units\n","\n","    # Activation function\n","    if activation is None:\n","      activation = Sigmoid()\n","    self.activation = activation\n","\n","    # Initialization rule\n","    self.init_rule = init_rule\n","\n","    # Initialize units\n","    self._init_units()\n","\n","    # Health check\n","    self._health_check()\n","\n","  def _save_foward_transform(self, x, y):\n","    self.last_input = x\n","    self.last_output = y\n","\n","  def _init_units(self):\n","    '''Initialize units of Layer'''\n","\n","    # Layer list\n","    self.units = []\n","\n","    # Iterate of amount of units\n","    for unit_id in range(self.num_units):\n","      self.units.append(\n","          Perceptron(\n","              input_size=self.input_size,\n","              init_rule=self.init_rule,\n","              activation=self.activation\n","          )\n","      )\n","  \n","  def _health_check(self):\n","    '''Perform a health check prediction'''\n","\n","    # 1D (input_size)\n","    X = np.random.rand(self.input_size)\n","    self(X)\n","\n","    # 2D (4 items, input_size)\n","    X = np.random.rand(4, self.input_size)\n","    self(X)\n","\n","\n","  def set_weights(self, weights: np.ndarray):\n","    '''Update weights per unit\n","\n","      Params:\n","        weights (np.ndarray): array of weights; size: (num_units, len(unit.weights))\n","    '''\n","\n","    # Assure weights have same length as number of units\n","    assert len(weights) == self.num_units, \"Array of weigths must have shape (num_units, len(unit.weights))\"\n","\n","    for unit_weights, unit in zip(weights, self.units):\n","\n","      # Update weights for each unit\n","      unit.set_weights(unit_weights)\n","\n","  def get_weights(self) -> np.ndarray:\n","    '''Return a array of a copy of current weights per unit'''\n","\n","    units_weights = []\n","\n","    for unit in self.units:\n","\n","      # Append unit weights\n","      units_weights.append(unit.get_weights())\n","\n","    # Return weights\n","    return np.array(units_weights)\n","\n","  def backward(self, delta, value):\n","    '''\n","    Apply backward propagation of the layer\n","    '''\n","\n","    # Get gradient\n","    grad = self.activation.gradient(value)\n","\n","    # Return new delta\n","    new_delta = (delta @ self.get_weights())[:, 1:] * grad\n","\n","    return new_delta\n","\n","  def forward(self, X: np.ndarray) -> np.ndarray:\n","    '''Make a batch or single prediction\n","    \n","      Params:\n","        X (np.ndarray): Batch of items (2D array) or a item (1D array)\n","        \n","      Returns:\n","        output (np.ndarray) logits\n","    '''\n","    \n","    # Initalizate logits list (size of num units)\n","    logits = []\n","\n","    for unit in self.units:\n","      \n","      # Apply foward in perceptron unit\n","      logit = unit(X)\n","\n","      # Save logit\n","      logits.append(logit)\n","\n","    # Return transpose logits\n","    logits = np.array(logits).T\n","\n","    return logits\n","\n","  def __call__(self, X: np.ndarray) -> np.ndarray:\n","    '''Make a batch or single prediction (runs forward method)\n","    \n","      Params:\n","        X (np.ndarray): Batch of items (2D array) or a item (1D array)\n","        \n","      Returns:\n","        output (np.ndarray) logits\n","    '''\n","\n","    y = self.forward(X)\n","\n","    self._save_foward_transform(X, y)\n","\n","    return y"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K5Y58Hcm7bqO"},"source":["### MultiLayerPerceptron Class"]},{"cell_type":"code","metadata":{"id":"GYyLmMY64mrq","executionInfo":{"status":"ok","timestamp":1630506608752,"user_tz":180,"elapsed":494,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["class MultiLayerPerceptron():\n","\n","  def __init__(self, layers: list, loss_func = None):\n","    '''Initializes MultiLayerPerceptron Model\n","    \n","      Params:\n","        layers (list): list of perceptron layers\n","        loss_func (func): loss function to be applied\n","      '''\n","\n","    # Perceptron Layers\n","    self.layers = layers\n","    self.num_layers = len(layers)\n","\n","    # Input and output sizes\n","    self.input_size = layers[0].input_size\n","    self.output_size = layers[-1].output_size\n","\n","    # Save loss\n","    if loss_func is None:\n","      self.loss_func = MSE()\n","    else:\n","      self.loss_func = loss_func\n","\n","    # Health check\n","    self._health_check()\n","  \n","  def _health_check(self):\n","    '''Perform a health check prediction'''\n","\n","    # Get first layer input size\n","    selfinput_size = self\n","\n","    # 1D (input_size)\n","    X = np.random.rand(self.input_size)\n","    self(X)\n","\n","    # 2D (4 items, input_size)\n","    X = np.random.rand(4, self.input_size)\n","    self(X)\n","\n","  def _extend(self, vec):\n","    \n","    return np.hstack([np.ones((vec.shape[0], 1)), vec])\n","\n","  def _backpropagate(self, x_input: np.ndarray, predicted_y: np.ndarray, \n","                     reference_y: np.ndarray, learning_rate: float):\n","    '''\n","    Backpropagate loss to update each perceptron set of weigths in\n","    each layer of the model\n","\n","    Params:\n","      x_input (np.ndarray): batch of input x\n","      reference_y (np.ndarray): batch of reference y's\n","      predicted_y (np.ndarray): batch of predicted y's\n","      learning_rate (float): learning rate param\n","    '''\n","\n","    # Get first delta\n","    delta = predicted_y - reference_y\n","\n","    # Get last predicted layer output\n","    last_output = predicted_y\n","\n","    # Initialize weights dict variations\n","    dWs = {}\n","\n","    # Iterate backwards over layers\n","    for i in range(-1, -len(self.layers), -1):\n","      \n","      # Get layer last output\n","      last_output = self.layers[i - 1].last_output\n","\n","      # Update layer weights variation\n","      dWs[i] = delta.T @ self._extend(last_output)\n","\n","      # Get new delta\n","      delta = self.layers[i].backward(delta, last_output)\n","\n","    # Update layer weights variation (first layer)\n","    dWs[-self.num_layers] = delta.T @ self._extend(x_input)\n","\n","    # Update each layer weights\n","    for k, dW in dWs.items():\n","      \n","      # Get current weights\n","      weights = self.layers[k].get_weights()\n","      weights -= learning_rate * dW\n","\n","      # Update weights\n","      self.layers[k].set_weights(weights)\n","\n","  def get_weights(self) -> np.ndarray:\n","    '''Return a list of arrays of a copy of current weights per layer and unit'''\n","\n","    layer_weights = []\n","\n","    for layer in self.layers:\n","\n","      # Append unit weights\n","      layer_weights.append(layer.get_weights())\n","\n","    # Return weights\n","    return layer_weights\n","\n","  def _get_batch(self, X: np.ndarray, y: np.ndarray, batch_size: int):\n","    '''Generator of batch of items from X and y input data'''\n","\n","    # X and y lengths must match\n","    assert len(X) == len(y), f\"X (len = {len(X)}) and y (len = {len(y)}) lengths must match\"\n","\n","    # Produce batches\n","    batches = []\n","\n","    # For each batch step append items\n","    for step in range(len(X)//batch_size + 2):\n","      \n","      # Get batch\n","      X_batch = X[step*batch_size:(step+1)*batch_size]\n","      y_batch = y[step*batch_size:(step+1)*batch_size]\n","\n","      if len(X_batch) == 0: break\n","\n","      batches.append({\n","          'X': X_batch,\n","          'y': y_batch\n","      })\n","\n","    # Generate each batch pre-computed\n","    for batch in batches:\n","\n","      # Return item\n","      yield batch\n","\n","  def fit(self, X: np.ndarray, y: np.ndarray, learning_rate: float = 0.1,\n","          max_epochs: int = 5, stop_threshold: float = 1e-3, batch_size: int = 1):\n","    '''\n","    Fit the MLP model using a max_epochs steps, or when the stop_threshold\n","    is met\n","\n","      Params:\n","        X (np.ndarray): a array of inputs, each input must match model input_size (number of features)\n","        y (np.ndarray): a array of target values (labels)\n","        learning_rate (float): hyperparameter to be used on backpropagation\n","        max_epochs (int): number of maximum epochs to iterate\n","        stop_threshold (float): number to be used to stop training if epoch loss is lower\n","        batch_size (int): size of each batch for the training steps\n","\n","      Returns:\n","        history (dict): A dictionary containing training data over training as epoch loss\n","    '''\n","\n","    # Assure X and y has same size\n","    assert len(X) == len(y), f\"X (len = {len(X)}) and y (len = {len(y)}) lengths must match\"\n","    assert len(y[0]) == self.layers[-1].num_units, f\"y_i (len = {len(y[0])}) and output layer (len = {self.layers[-1].num_units}) lengths must match\"\n","\n","    # Epoch iterator\n","    iterator = tqdm(range(max_epochs))\n","\n","    # Num items\n","    num_items = len(y)\n","\n","    # History of train\n","    history = {'loss': []}\n","\n","    for epoch in iterator:\n","\n","      # Log epoch\n","      iterator.set_description(f'Epoch {epoch+1}/{max_epochs}')\n","\n","      # Initialize epoch loss (mean absolute value)\n","      epoch_loss = 0\n","      \n","      # Iterate over all items\n","      for batch in self._get_batch(X, y, batch_size):\n","\n","        # Retriever X and y batch\n","        input_x = batch['X']\n","        reference_y = batch['y']\n","        \n","        # Make prediction\n","        predicted_y = self(input_x)\n","\n","        # Calculate error (loss)\n","        loss = self.loss_func.calculate(reference_y, predicted_y)\n","\n","        # Add to epoch loss\n","        epoch_loss += batch_size * loss/num_items\n","\n","        # Update weights\n","        # self._backpropagate(reference_y, predicted_y, learning_rate)\n","        self._backpropagate(input_x, predicted_y, reference_y, learning_rate)\n","      \n","      # Log epoch loss\n","      iterator.set_postfix({'loss': epoch_loss})\n","\n","      # Append history\n","      history['loss'].append(epoch_loss)\n","\n","      # Stop Threshold\n","      if epoch_loss < stop_threshold:\n","        print(f'>> Loss met stop condition (at epoch {epoch+1}): loss = {epoch_loss} < {stop_threshold}')\n","        break\n","\n","    return history\n","\n","  def forward(self, X: np.ndarray) -> np.ndarray:\n","    '''Make a batch or single prediction\n","    \n","      Params:\n","        X (np.ndarray): Batch of items (2D array) or a item (1D array)\n","        \n","      Returns:\n","        output (np.ndarray) logits\n","    '''\n","\n","    # Apply forward on each sequential layer\n","    for layer in self.layers:\n","      X = layer(X)\n","    \n","    return X\n","\n","  def __call__(self, X: np.ndarray) -> np.ndarray:\n","    '''Make a batch or single prediction (runs forward method)\n","    \n","      Params:\n","        X (np.ndarray): Batch of items (2D array) or a item (1D array)\n","        \n","      Returns:\n","        output (np.ndarray) logits\n","    '''\n","\n","    return self.forward(X)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yga2RavVgZOf"},"source":["### XOR Problem"]},{"cell_type":"markdown","metadata":{"id":"YsAZVWEi0UIS"},"source":["#### Dataset"]},{"cell_type":"code","metadata":{"id":"W5OO6cNCYTUj","executionInfo":{"status":"ok","timestamp":1630506608752,"user_tz":180,"elapsed":9,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["X = np.array([[1, 1], [0, 0], [0, 1], [1, 0]])\n","y = np.array([[0], [0], [1], [1]])"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6DO0LEch0P8S"},"source":["#### Build Model"]},{"cell_type":"code","metadata":{"id":"eR3iI3P9zF_S","executionInfo":{"status":"ok","timestamp":1630506608753,"user_tz":180,"elapsed":9,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["# Layers\n","layer1 = PerceptronLayer(input_size=2, units=4, init_rule='rand', activation=Relu())\n","layer2 = PerceptronLayer(input_size=4, units=2, init_rule='rand', activation=Swish())\n","layer3 = PerceptronLayer(input_size=2, units=1, init_rule='rand', activation=Sigmoid())\n","\n","layers = [layer1, layer2, layer3]\n","\n","# Model\n","model = MultiLayerPerceptron(layers = layers, loss_func=MSE())"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g6AIv9wd0XB1"},"source":["#### Train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVrZiX0G0d6A","executionInfo":{"status":"ok","timestamp":1630506608754,"user_tz":180,"elapsed":9,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"cecaf060-ad91-4c75-f7a1-b4d743584b86"},"source":["# Model predictions before train:\n","\n","print('>> Predictions before train:')\n","model(X)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":[">> Predictions before train:\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.51623391],\n","       [0.37841334],\n","       [0.46270858],\n","       [0.47317163]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["ba1fa9f3e0534780a9accd2bb1a5f4e6","925f7358e08840fda19c817875a80915","735578905c9942398bc3cb0de39b9bab","e40ef7b61e404cf0b855e393d0bd733a","0c91b06b1f3b404f80dab5cc6e97d9d2","0ecc2a5eb5fc44b5b214a314bf831091","2fbf8ac369d84aa59717a68446c7ed80","b8f8f02853b24afc9a53fe3307b815fb","57385cf7acb446c5af5f4e193729a81f","769b27f8320d46fa908e6b56a6edca67","6358ccb6eff74e4b8e4e720b62515395"]},"id":"poBJAmJWYisF","executionInfo":{"status":"ok","timestamp":1630506611734,"user_tz":180,"elapsed":2986,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"154a0fe6-0dbe-44e3-95e9-aa0be1730f3e"},"source":["hist = model.fit(X, y, max_epochs=2000, batch_size=1)"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba1fa9f3e0534780a9accd2bb1a5f4e6","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/2000 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":[">> Loss met stop condition (at epoch 239): loss = 0.0009933750150525284 < 0.001\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKAXFljd0lsH","executionInfo":{"status":"ok","timestamp":1630506611735,"user_tz":180,"elapsed":8,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"a7f255eb-e199-4919-8c1e-5ac9513e7555"},"source":["print('>> Predictions after train:')\n","model(X)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":[">> Predictions after train:\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.03445139],\n","       [0.04707353],\n","       [0.95815299],\n","       [0.95366496]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"Ie-kX0Xa0n-I"},"source":["#### Training Visualization"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"Qtjvr9DhYiwr","executionInfo":{"status":"ok","timestamp":1630506613473,"user_tz":180,"elapsed":1743,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"f8776518-36df-4d65-f0af-c8c77a56c4a7"},"source":["fig = px.line(y=hist['loss'])\n","fig.update_layout(\n","    title = 'XOR | Loss vs Epochs',\n","    xaxis_title = 'Epoch',\n","    yaxis_title = 'Loss'\n",")"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"711b071f-7356-4ad2-bc31-27a78c19382d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"711b071f-7356-4ad2-bc31-27a78c19382d\")) {\n","                    Plotly.newPlot(\n","                        '711b071f-7356-4ad2-bc31-27a78c19382d',\n","                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"y=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"xaxis\": \"x\", \"y\": [0.1261371282972063, 0.12576624907165404, 0.125469536056691, 0.12522879464374842, 0.12502997515897904, 0.12486228032070343, 0.12471744717402342, 0.12458917620211588, 0.12447268157995928, 0.12436433940085233, 0.12426141411160205, 0.12416184676611323, 0.12406409177073693, 0.12396699143969651, 0.12386967988961475, 0.12377150960948832, 0.1236719954968981, 0.12357077230826684, 0.12346756238343463, 0.12336215121965353, 0.12325436902720538, 0.12314407683124463, 0.12303115601895256, 0.12291550048911756, 0.12279701075983303, 0.12267558954250582, 0.12255113840726194, 0.12242355525426718, 0.12229273237377125, 0.12215855492972628, 0.12202089974140147, 0.12187963426741764, 0.12173461571930319, 0.12158569024873522, 0.12143269216539887, 0.12127544315187713, 0.1211137514489469, 0.12094741098968768, 0.1207762004643588, 0.1205998823004066, 0.12041820154348268, 0.12023088462618606, 0.12003763801152544, 0.11983814669795392, 0.11963207257233045, 0.1194190525963795, 0.11919869681119952, 0.11897058614314882, 0.11873426999304978, 0.11848926358912842, 0.11823504508247495, 0.11797105236211572, 0.11769667956506619, 0.11741127325505299, 0.1171141282420289, 0.11680448301326146, 0.11648151474579921, 0.1161443338696917, 0.11580850084918978, 0.11554124338301, 0.11526522194957088, 0.1149799511238196, 0.11468492438373468, 0.11437961156553189, 0.11406345657935317, 0.11373587534033161, 0.11339625388849268, 0.1130439466865625, 0.11267827509832623, 0.11229852606238484, 0.1119039509875178, 0.11149376490673399, 0.11106714593772143, 0.11062323510790505, 0.11016113661268402, 0.10967991858550807, 0.10917861446798612, 0.10865622507675574, 0.10811172147075256, 0.10754404872697526, 0.10695213073380017, 0.10633487610709504, 0.1056911853243466, 0.10501995915412843, 0.10432010843079621, 0.10359056518567963, 0.1028302950948787, 0.10203831113924958, 0.10121368829432852, 0.10035557897812797, 0.09946322888594883, 0.09853599273866012, 0.09757334937167372, 0.09657491550578814, 0.09554045747988901, 0.09446990020206929, 0.09336333260286574, 0.09222100896286649, 0.09104334564371291, 0.08983091297695342, 0.08858442235157628, 0.0873047088714074, 0.08599271030210136, 0.08464944336145688, 0.08327597869024468, 0.08187341603917087, 0.08044286129337024, 0.07898540691280595, 0.0775021171936312, 0.07599401946573311, 0.07446210196252157, 0.07290731866695571, 0.07133060099290332, 0.06973287574118386, 0.06811508840609551, 0.06647823062187105, 0.06482337033934055, 0.06315168321106128, 0.06146448363068547, 0.05976325390729773, 0.05804967014450873, 0.056459430505318764, 0.05501641172367931, 0.053566449383778136, 0.052109308419655206, 0.05064580063857112, 0.049177298286867656, 0.047705539573344016, 0.046232541725400034, 0.04476055149255402, 0.043292007054424764, 0.04182950186717194, 0.04037574721556837, 0.03893353268322659, 0.03750568481847536, 0.03609502480421868, 0.03470432622128642, 0.03333627412001404, 0.031993426619192834, 0.030678180156233546, 0.029392739337999206, 0.028139092111144202, 0.026918990708178957, 0.025733938554573305, 0.024585183064215574, 0.023473714022565248, 0.02240026707089688, 0.021365331667766125, 0.020369162816789348, 0.01941179581030905, 0.01849306324063239, 0.017612613566442094, 0.016769930583018428, 0.01596435322253583, 0.015199209969357228, 0.014469332636382223, 0.013773730020273465, 0.013111351709004126, 0.012481080519725643, 0.011881757245783837, 0.011312197713066092, 0.010771205683672836, 0.010283154176454512, 0.009826660235170141, 0.009394226846548023, 0.008984105419219996, 0.008594888903606877, 0.008225358631887246, 0.007874413522936647, 0.007541035963473035, 0.007224274479709804, 0.0069232342401390565, 0.0066370712746672755, 0.006364988498681624, 0.00610623264676256, 0.005860091693205369, 0.005625892557415735, 0.005402998996054711, 0.005190809632881185, 0.00499473830344646, 0.004817439476291012, 0.0046494243405863465, 0.004489651876931979, 0.004337378238066573, 0.004192029395851662, 0.004053134794543465, 0.003920291427076553, 0.0037931436141046553, 0.003671371111622562, 0.0035546817492051897, 0.00344280660175317, 0.003335496625510195, 0.0032325201751919413, 0.003133661077201337, 0.0030387170728191745, 0.0029474985211345997, 0.0028598272936884235, 0.0027755358168345162, 0.0026944662319202672, 0.0026164696519602555, 0.0025414054989197797, 0.0024691409093418517, 0.0023995501985708194, 0.0023325143756574027, 0.0022679207024123007, 0.0022056622911500933, 0.0021456377365211983, 0.002087750777521952, 0.002031909986342037, 0.0019780284811789046, 0.0019260236605423342, 0.001875816956901866, 0.0018273336078082135, 0.0017805024428550861, 0.0017352556850482692, 0.0016915287653190957, 0.0016492601490657435, 0.0016083911737308416, 0.001568865896531933, 0.0015306309515544193, 0.0014936354154974829, 0.0014578306814337903, 0.0014231703400052254, 0.0013896100675305034, 0.001357107520548122, 0.001325622236359509, 0.001295115539174655, 0.0012655504514949335, 0.0012368916103976607, 0.0012091051884128427, 0.0011821588187064997, 0.0011560215243060362, 0.0011306636511225626, 0.001106056804542541, 0.0010821737893769588, 0.0010589885529709113, 0.0010364761312896288, 0.0010146125978093695, 0.0009933750150525284], \"yaxis\": \"y\"}],\n","                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"XOR | Loss vs Epochs\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('711b071f-7356-4ad2-bc31-27a78c19382d');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"gMKhkM2p01ge"},"source":["### Auto-Encoder Problem"]},{"cell_type":"markdown","metadata":{"id":"rObKQKlk1BF8"},"source":["#### Dataset"]},{"cell_type":"code","metadata":{"id":"JOAIz1rQ06tI","executionInfo":{"status":"ok","timestamp":1630506613474,"user_tz":180,"elapsed":9,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["def identity_dataset(size: int = 9) -> tuple:\n","  '''\n","  Builds a dataset for auto-encoder training, in which\n","  the data (X <=> y) represents rows of identity matrix\n","\n","  Ex: size = 3\n","\n","    X = y = [\n","      [1, 0, 0],\n","      [0, 1, 0],\n","      [0, 0, 1]\n","    ]\n","  '''\n","\n","  X = np.identity(size)\n","  y = np.identity(size)\n","\n","  return X, y"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"t2o_3XQJ1uCo","executionInfo":{"status":"ok","timestamp":1630506613474,"user_tz":180,"elapsed":8,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["def visualize_matrix(X):\n","\n","  return pd.DataFrame(X)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"oG7Cwbhf1nLk","executionInfo":{"status":"ok","timestamp":1630506613474,"user_tz":180,"elapsed":8,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["X_8, y_8 = identity_dataset(8)\n","X_15, y_15 = identity_dataset(15)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IFDTxEJZ17zv"},"source":["#### Build Models"]},{"cell_type":"code","metadata":{"id":"UGS7JZkF1oQn","executionInfo":{"status":"ok","timestamp":1630506613475,"user_tz":180,"elapsed":8,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["# Layers\n","layer1 = PerceptronLayer(input_size=8, units=3, init_rule='rand', activation=Swish())\n","layer2 = PerceptronLayer(input_size=3, units=8, init_rule='rand', activation=Relu())\n","\n","layers = [layer1, layer2]\n","\n","# Model\n","model_8 = MultiLayerPerceptron(layers = layers, loss_func=MSE())"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgJi_6oM2P9H","executionInfo":{"status":"ok","timestamp":1630506613475,"user_tz":180,"elapsed":8,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}}},"source":["# Layers\n","layer1 = PerceptronLayer(input_size=15, units=4, init_rule='rand', activation=Swish())\n","layer2 = PerceptronLayer(input_size=4, units=15, init_rule='rand', activation=Relu())\n","\n","layers = [layer1, layer2]\n","\n","# Model\n","model_15 = MultiLayerPerceptron(layers = layers, loss_func=MSE())"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fxXK9Hyn2oYP"},"source":["#### Train"]},{"cell_type":"markdown","metadata":{"id":"LUb3EbWy2lyY"},"source":["##### Before Train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"0TT76ST52S_n","executionInfo":{"status":"ok","timestamp":1630506613475,"user_tz":180,"elapsed":8,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"b4182139-be67-47c4-f3de-096f7cee7c65"},"source":["# Model predictions before train:\n","\n","print('>> Predictions before train (Auto-Encoder 8)')\n","visualize_matrix(model_8(X_8))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":[">> Predictions before train (Auto-Encoder 8)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.644295</td>\n","      <td>0.0</td>\n","      <td>1.339091</td>\n","      <td>0.479582</td>\n","      <td>0.0</td>\n","      <td>1.290386</td>\n","      <td>1.874149</td>\n","      <td>0.581963</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.408113</td>\n","      <td>0.0</td>\n","      <td>0.524639</td>\n","      <td>0.061198</td>\n","      <td>0.0</td>\n","      <td>0.305845</td>\n","      <td>0.942494</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.577586</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.945446</td>\n","      <td>1.012980</td>\n","      <td>0.149977</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.697407</td>\n","      <td>0.0</td>\n","      <td>1.014143</td>\n","      <td>0.369109</td>\n","      <td>0.0</td>\n","      <td>0.785715</td>\n","      <td>1.620785</td>\n","      <td>0.236968</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.691881</td>\n","      <td>0.0</td>\n","      <td>1.847840</td>\n","      <td>1.374694</td>\n","      <td>0.0</td>\n","      <td>1.357167</td>\n","      <td>0.946041</td>\n","      <td>0.908644</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.368284</td>\n","      <td>0.109567</td>\n","      <td>0.0</td>\n","      <td>1.808394</td>\n","      <td>2.224405</td>\n","      <td>0.791059</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1.404038</td>\n","      <td>0.0</td>\n","      <td>1.654793</td>\n","      <td>1.185089</td>\n","      <td>0.0</td>\n","      <td>1.299082</td>\n","      <td>0.551361</td>\n","      <td>0.824311</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.715989</td>\n","      <td>0.0</td>\n","      <td>0.579684</td>\n","      <td>0.309146</td>\n","      <td>0.0</td>\n","      <td>0.201187</td>\n","      <td>0.406553</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0    1         2         3    4         5         6         7\n","0  0.644295  0.0  1.339091  0.479582  0.0  1.290386  1.874149  0.581963\n","1  0.408113  0.0  0.524639  0.061198  0.0  0.305845  0.942494  0.000000\n","2  0.000000  0.0  0.577586  0.000000  0.0  0.945446  1.012980  0.149977\n","3  0.697407  0.0  1.014143  0.369109  0.0  0.785715  1.620785  0.236968\n","4  1.691881  0.0  1.847840  1.374694  0.0  1.357167  0.946041  0.908644\n","5  0.000000  0.0  1.368284  0.109567  0.0  1.808394  2.224405  0.791059\n","6  1.404038  0.0  1.654793  1.185089  0.0  1.299082  0.551361  0.824311\n","7  0.715989  0.0  0.579684  0.309146  0.0  0.201187  0.406553  0.000000"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"p-a5aM9B2U9p","executionInfo":{"status":"ok","timestamp":1630506613760,"user_tz":180,"elapsed":291,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"eb25f3d6-e20c-402a-e135-b72f788579fa"},"source":["print('>> Expected Outputs (Auto-Encoder 8)')\n","visualize_matrix(y_8)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":[">> Expected Outputs (Auto-Encoder 8)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     0    1    2    3    4    5    6    7\n","0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n","2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n","3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n","4  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n","5  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n","6  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n","7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Qa8BV8vT2gX3","executionInfo":{"status":"ok","timestamp":1630506613761,"user_tz":180,"elapsed":14,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"9be2ad4e-457e-4e59-ccab-ac4b2d7a5909"},"source":["# Model predictions before train:\n","\n","print('>> Predictions before train (Auto-Encoder 15)')\n","visualize_matrix(model_15(X_15))"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":[">> Predictions before train (Auto-Encoder 15)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.218954</td>\n","      <td>0.568630</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.119015</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.006026</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.402666</td>\n","      <td>0.000000</td>\n","      <td>0.627813</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.264905</td>\n","      <td>0.386194</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.083207</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.266482</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.573474</td>\n","      <td>0.000000</td>\n","      <td>0.873773</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.261920</td>\n","      <td>0.341132</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.120478</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.852118</td>\n","      <td>0.963270</td>\n","      <td>1.566816</td>\n","      <td>0.015135</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.476437</td>\n","      <td>0.152732</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.102784</td>\n","      <td>0.162329</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.448002</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.742998</td>\n","      <td>0.000000</td>\n","      <td>1.129389</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.216022</td>\n","      <td>0.024076</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.303166</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.183336</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.675669</td>\n","      <td>0.000000</td>\n","      <td>1.173817</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.956786</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.016430</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.065319</td>\n","      <td>1.187055</td>\n","      <td>0.756909</td>\n","      <td>0.302496</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.567887</td>\n","      <td>0.353632</td>\n","      <td>0.0</td>\n","      <td>0.169638</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.690323</td>\n","      <td>0.323872</td>\n","      <td>1.304392</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.0</td>\n","      <td>0.193185</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.544689</td>\n","      <td>0.058023</td>\n","      <td>0.0</td>\n","      <td>0.429362</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.809264</td>\n","      <td>0.000000</td>\n","      <td>1.357500</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.0</td>\n","      <td>0.034503</td>\n","      <td>0.213680</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.290747</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.201595</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.597582</td>\n","      <td>0.062665</td>\n","      <td>1.011351</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.390990</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.150988</td>\n","      <td>0.185399</td>\n","      <td>0.631619</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.733351</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.230001</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.148767</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.346288</td>\n","      <td>0.705272</td>\n","      <td>0.563144</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.131291</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.556890</td>\n","      <td>0.325171</td>\n","      <td>0.0</td>\n","      <td>0.573258</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.796985</td>\n","      <td>0.175806</td>\n","      <td>1.330864</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.284765</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.283470</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.358351</td>\n","      <td>0.268110</td>\n","      <td>1.072985</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>1.262624</td>\n","      <td>0.550619</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.137188</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.731695</td>\n","      <td>0.930001</td>\n","      <td>1.203540</td>\n","      <td>0.245701</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.671850</td>\n","      <td>0.125954</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.388379</td>\n","      <td>0.248679</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.401648</td>\n","      <td>1.251061</td>\n","      <td>1.218041</td>\n","      <td>0.580970</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     0         1         2         3   ...        11        12        13        14\n","0   0.0  0.218954  0.568630  0.000000  ...  0.000000  1.402666  0.000000  0.627813\n","1   0.0  0.264905  0.386194  0.000000  ...  0.000000  1.573474  0.000000  0.873773\n","2   0.0  0.000000  1.261920  0.341132  ...  0.852118  0.963270  1.566816  0.015135\n","3   0.0  0.476437  0.152732  0.000000  ...  0.000000  1.742998  0.000000  1.129389\n","4   0.0  0.216022  0.024076  0.000000  ...  0.000000  1.675669  0.000000  1.173817\n","5   0.0  0.000000  0.956786  0.000000  ...  0.065319  1.187055  0.756909  0.302496\n","6   0.0  0.000000  0.000000  0.000000  ...  0.000000  1.690323  0.323872  1.304392\n","7   0.0  0.193185  0.000000  0.000000  ...  0.000000  1.809264  0.000000  1.357500\n","8   0.0  0.034503  0.213680  0.000000  ...  0.000000  1.597582  0.062665  1.011351\n","9   0.0  0.000000  0.390990  0.000000  ...  0.000000  1.150988  0.185399  0.631619\n","10  0.0  0.000000  0.733351  0.000000  ...  0.000000  1.346288  0.705272  0.563144\n","11  0.0  0.000000  0.131291  0.000000  ...  0.000000  1.796985  0.175806  1.330864\n","12  0.0  0.000000  0.284765  0.000000  ...  0.000000  1.358351  0.268110  1.072985\n","13  0.0  0.000000  1.262624  0.550619  ...  0.731695  0.930001  1.203540  0.245701\n","14  0.0  0.000000  0.671850  0.125954  ...  0.401648  1.251061  1.218041  0.580970\n","\n","[15 rows x 15 columns]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"0PbvI11M2jyZ","executionInfo":{"status":"ok","timestamp":1630506613761,"user_tz":180,"elapsed":10,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"e13b6bde-f15a-472c-ce5e-9e0a03386966"},"source":["print('>> Expected Outputs (Auto-Encoder 15)')\n","visualize_matrix(y_15)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":[">> Expected Outputs (Auto-Encoder 15)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     0    1    2    3    4    5    6    7    8    9    10   11   12   13   14\n","0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","1   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","2   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","3   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","4   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","5   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","6   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n","8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n","9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n","10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n","11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0\n","12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n","13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0\n","14  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"FNv5diu12pgM"},"source":["##### Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98,"referenced_widgets":["a6b8f7f21a6c463683a68a562619b855","e23be2aa71e14bf6b40c32aea769a838","d7b31b440cf34c9aa9f6c268eeb6fe92","f25750b7f46b4164b1a36eddc8af1a86","e773f9e9f9ee4792b590ca2eccf15f9f","7a20900bca96427aad7bce551cdf0077","ad106899b9b8484eb73d8923d87b1209","3876d31e048b4c60b0d7f3ef8f038fb6","1de47dc0b0a8421ebf7ee33e9367e534","b17ab1364a4741a19a60c533f2986c4d","7ef037d1171d420caad9613b899e4771","e7d61a05b6fd48e9b9c0d3745204e865","5ada9cd4e58e477380be9664197af95a","f56790f770fa4eecab0097b8d4e918d4","a88167b4a2704354b0db1c4c36e85053","befb2fdc1b0747d68cb80cdd2860ce6b","3af60b82effa422eb69a9021a5b9d2fb","7d6903a799824ee88292a936df6e59ba","38509af77ce040b49110a4a3c449386d","eb1116aadeb9472bba02ca2846578370","5b2f7807d32940c0ad70546b7ecc4962","64747822e92149db8f46b619b0a6a333"]},"id":"bGPlNgqG2VKH","executionInfo":{"status":"ok","timestamp":1630506670495,"user_tz":180,"elapsed":56743,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"f5fb0a22-1f91-4efd-e734-b57b8fb7eba9"},"source":["hist_8 = model_8.fit(X_8, y_8, max_epochs=4000, batch_size=1, learning_rate=0.1)\n","hist_15 = model_15.fit(X_15, y_15, max_epochs=4000, batch_size=1, learning_rate=0.1)"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6b8f7f21a6c463683a68a562619b855","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4000 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7d61a05b6fd48e9b9c0d3745204e865","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4000 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":[">> Loss met stop condition (at epoch 143): loss = 0.0009641382923742789 < 0.001\n"]}]},{"cell_type":"markdown","metadata":{"id":"L0mbrywt2-0f"},"source":["##### After Train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"id":"t9K-_L3X2lbd","executionInfo":{"status":"ok","timestamp":1630506670496,"user_tz":180,"elapsed":39,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"bbc08058-9fa9-439d-d30e-e70c296be9ef"},"source":["# Model predictions after train:\n","\n","print('>> Predictions after train (Auto-Encoder  8)')\n","visualize_matrix(model_8(X_8))"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":[">> Predictions after train (Auto-Encoder  8)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.933008</td>\n","      <td>0.075251</td>\n","      <td>0.000000</td>\n","      <td>0.439999</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>0.856953</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.009392</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.572779</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.993762</td>\n","      <td>0.000000</td>\n","      <td>0.000340</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.007442</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.147062</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000754</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.000000</td>\n","      <td>0.062842</td>\n","      <td>0.000767</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.954543</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1         2  ...         5         6         7\n","0  0.933008  0.075251  0.000000  ...  0.000000  0.000000  0.000000\n","1  0.000000  0.856953  0.000000  ...  0.000000  0.000000  0.000000\n","2  0.000000  0.000000  1.009392  ...  0.000000  0.000000  0.000000\n","3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n","4  0.000000  0.000000  0.000000  ...  0.000000  0.000340  0.000000\n","5  0.000000  0.000000  0.007442  ...  1.147062  0.000000  0.000000\n","6  0.000000  0.000000  0.000000  ...  0.000000  1.000754  0.000000\n","7  0.000000  0.062842  0.000767  ...  0.000000  0.000000  0.954543\n","\n","[8 rows x 8 columns]"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":531},"id":"75D5Sk8O3Fsj","executionInfo":{"status":"ok","timestamp":1630506670497,"user_tz":180,"elapsed":11,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"48c8c326-c58c-4f82-e59c-0f879ca0e3af"},"source":["# Model predictions after train:\n","\n","print('>> Predictions after train (Auto-Encoder 15)')\n","visualize_matrix(model_15(X_15))"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":[">> Predictions after train (Auto-Encoder 15)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.998483</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.000000</td>\n","      <td>0.977634</td>\n","      <td>0.000000</td>\n","      <td>0.015886</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.002390</td>\n","      <td>0.000000</td>\n","      <td>0.014473</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.983509</td>\n","      <td>0.000000</td>\n","      <td>0.005273</td>\n","      <td>0.011053</td>\n","      <td>0.018424</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.983503</td>\n","      <td>0.000000</td>\n","      <td>0.013599</td>\n","      <td>0.000000</td>\n","      <td>0.012147</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.003807</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.003579</td>\n","      <td>0.000000</td>\n","      <td>0.941165</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.013959</td>\n","      <td>0.042126</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.006767</td>\n","      <td>0.000000</td>\n","      <td>0.977027</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.025459</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.991904</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.008614</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.013895</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.997098</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.996705</td>\n","      <td>0.000000</td>\n","      <td>0.032539</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.006526</td>\n","      <td>0.957067</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.013843</td>\n","      <td>0.000000</td>\n","      <td>0.025940</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.000000</td>\n","      <td>0.036364</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.018257</td>\n","      <td>0.009262</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.015453</td>\n","      <td>0.923791</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.003389</td>\n","      <td>0.004496</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.995003</td>\n","      <td>0.000000</td>\n","      <td>0.002304</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.993351</td>\n","      <td>0.002826</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.002659</td>\n","      <td>0.002706</td>\n","      <td>0.996273</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.007649</td>\n","      <td>0.007689</td>\n","      <td>0.001401</td>\n","      <td>0.008010</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.990419</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1         2   ...        12        13        14\n","0   0.998483  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n","1   0.000000  0.977634  0.000000  ...  0.000000  0.000000  0.000000\n","2   0.000000  0.000000  0.983509  ...  0.000000  0.000000  0.000000\n","3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n","4   0.000000  0.000000  0.003579  ...  0.000000  0.000000  0.000000\n","5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n","6   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.013895\n","7   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n","8   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n","9   0.000000  0.000000  0.000000  ...  0.013843  0.000000  0.025940\n","10  0.000000  0.036364  0.000000  ...  0.000000  0.000000  0.000000\n","11  0.000000  0.000000  0.003389  ...  0.000000  0.002304  0.000000\n","12  0.000000  0.000000  0.000000  ...  0.993351  0.002826  0.000000\n","13  0.000000  0.000000  0.000000  ...  0.002706  0.996273  0.000000\n","14  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.990419\n","\n","[15 rows x 15 columns]"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"xCnplP6CXoOK"},"source":["#### Visualizing Train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"ReViqW-a4tpU","executionInfo":{"status":"ok","timestamp":1630506671391,"user_tz":180,"elapsed":901,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"49344c73-f574-4433-c6cf-bc1a87a15988"},"source":["fig = px.line(y=hist_8['loss'])\n","fig.update_layout(\n","    title = 'Auto Encoder - 8 | Loss vs Epochs',\n","    xaxis_title = 'Epoch',\n","    yaxis_title = 'Loss'\n",")"],"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"e970a1b4-f8b1-4ca8-8c0b-6a79437690da\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"e970a1b4-f8b1-4ca8-8c0b-6a79437690da\")) {\n","                    Plotly.newPlot(\n","                        'e970a1b4-f8b1-4ca8-8c0b-6a79437690da',\n","                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"y=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scattergl\", \"xaxis\": \"x\", \"y\": [1.4534975870669857, 0.5658448783133314, 0.5184688986397029, 0.4984189796416605, 0.48786734121547715, 0.4787985449009991, 0.47649425580736693, 0.47403450860172147, 0.4684516551203268, 0.46274727982640934, 0.45513383764666304, 0.450086541589373, 0.4454977832059426, 0.4415611660544355, 0.4372852850575946, 0.43395933963122624, 0.43085123751742654, 0.42780839498978845, 0.42511710079283116, 0.4225699607415857, 0.42012726855843324, 0.4177736480028732, 0.41552413730791, 0.41335889771311607, 0.4112324198093339, 0.4091438310198138, 0.40730631418471447, 0.40374281122766176, 0.40198416559248773, 0.4001807221825406, 0.39836467100445005, 0.3965495571166476, 0.39474089119028327, 0.39301334591718273, 0.3903716841239258, 0.3887484742929323, 0.38708271279869805, 0.3854121517078995, 0.3837719644517296, 0.3815813113344502, 0.380106259946782, 0.37842227186796434, 0.37674419059612, 0.3752950448660537, 0.3737024612737435, 0.37212746881842834, 0.3707122274318343, 0.36906259195641816, 0.3676049370653511, 0.3662971323989909, 0.36487575798320554, 0.36356698145737176, 0.3621551963501999, 0.36084922357886934, 0.35963216269411524, 0.3583486161385757, 0.3570626375184787, 0.3557978164977507, 0.3546345318666751, 0.353420900138645, 0.35224562592261577, 0.35106139327324937, 0.34990226991273615, 0.3487707102630689, 0.347641042563504, 0.3465198719257286, 0.3454203625912706, 0.34434188869408566, 0.34327510684401175, 0.3422018785026419, 0.3411691142005715, 0.340126644126554, 0.3391186694966366, 0.3381030243769054, 0.33710768031931054, 0.3361268667455072, 0.3351545168321333, 0.33418734077959755, 0.3332350668035548, 0.3322928383974696, 0.33136106726580017, 0.33043840670306535, 0.3295204639439038, 0.32862072484509575, 0.32772485689837233, 0.32683552536722266, 0.325956510872406, 0.3250864491010679, 0.32422482209066555, 0.3233713216188332, 0.3225256988641728, 0.3216877258705263, 0.32085718570892646, 0.32003387025547353, 0.3192175798579857, 0.31840812331732066, 0.31760531779800677, 0.3168089886211162, 0.3160189689746138, 0.31523509958346563, 0.31445722837058243, 0.31368557702207545, 0.3129206023589307, 0.31216027186052503, 0.31140463095411375, 0.3106536667747516, 0.30990757429092897, 0.30916849352770615, 0.3084350014660336, 0.30770642434196543, 0.3069824344782926, 0.3062628501233531, 0.3055475511066819, 0.3048364444220579, 0.304129450427654, 0.3034264973716103, 0.30272751922261215, 0.3020324547856152, 0.3013412473005625, 0.3006538442109524, 0.2999701969835768, 0.29929026093703254, 0.2986139950658726, 0.2979413618580068, 0.2972723271065627, 0.29660685971834294, 0.29594493152101264, 0.2952865170708705, 0.29463159346273465, 0.2939801401431807, 0.29333213872812136, 0.2926875728255087, 0.2920464278637652, 0.29140869092639843, 0.291217592762014, 0.29028576156440067, 0.289228980284513, 0.28819286644891834, 0.2872022958464267, 0.28625274227831216, 0.2853377343872992, 0.2844517255026515, 0.28358761137798044, 0.2827396204035266, 0.28191164131222746, 0.28110417053886405, 0.28031203194865645, 0.27953335656499795, 0.27876274134824564, 0.2780373519355495, 0.2773455941700346, 0.27667011224190813, 0.2760048882157322, 0.2753705062779778, 0.2747454309687573, 0.27412688019958315, 0.2735141986983956, 0.2729070017913635, 0.2723049491417183, 0.27170773308379736, 0.2711150348343524, 0.27052206753129954, 0.2699397134185612, 0.2693633759412351, 0.2687910945690129, 0.26822188873205105, 0.2676552522825507, 0.26709092242679544, 0.26652876079851107, 0.2659686902524012, 0.26541066109363654, 0.2648546333085904, 0.2643005676518151, 0.26374842168501994, 0.2626754658567704, 0.26212840104612234, 0.26157709492280323, 0.26101902758309214, 0.26046304614923654, 0.2599097486244387, 0.2593589903351269, 0.25881058448104943, 0.25826438052924483, 0.25772026503990225, 0.25717815212645695, 0.2566379753889557, 0.2560996826873995, 0.25556323301741274, 0.2550285946352316, 0.2544991009811753, 0.25397244035828836, 0.25344763022698125, 0.25292453687831157, 0.2524031163938858, 0.25188335711935766, 0.2510116064468209, 0.2505130428865797, 0.24998937688001327, 0.24946345969526929, 0.24894027648392694, 0.24841989997057995, 0.2479021796148639, 0.24738700844642653, 0.24687432162091405, 0.2463640791199463, 0.24585625374332493, 0.24535082455742913, 0.2448477737146002, 0.24434708503489577, 0.2438487434155721, 0.24335273458977974, 0.24285904501131392, 0.24236766177186964, 0.24187857251812794, 0.24139176536209325, 0.2409069732526356, 0.2404245454599579, 0.23994464590353543, 0.23946701591298034, 0.23899156100350355, 0.23851824337050642, 0.23804704472351584, 0.23757795310199115, 0.2371109582924541, 0.23664605031141756, 0.23618321895740632, 0.23572245372020023, 0.23526374379905513, 0.2348070781467934, 0.23435244551417425, 0.23389983448819673, 0.23344923352392621, 0.233000630970927, 0.23255401509550674, 0.23210937270282722, 0.23166648578126792, 0.23122537125095521, 0.23053729417478716, 0.23011915785739998, 0.22967132643778462, 0.22922593856871773, 0.22878377942756822, 0.2283425924179091, 0.22790322525939197, 0.22746602655448805, 0.22703111517237873, 0.22659850986114347, 0.2261681855426829, 0.22574009852992044, 0.2253141981142759, 0.22489043199072234, 0.2244687488018703, 0.22404909929033434, 0.2236314367612512, 0.2232157171991191, 0.22280189921388932, 0.22238994390751102, 0.22197981470891695, 0.22157147720236178, 0.2211648989614641, 0.22076004939444838, 0.22035689960241217, 0.2199554222505706, 0.21955559145156278, 0.2191573826595816, 0.2187607725740592, 0.21836573905173418, 0.21797226102608022, 0.21758031843323133, 0.21718989214368006, 0.2168009638991487, 0.21641351625413263, 0.21602753252169013, 0.21564299672312012, 0.2152598935412116, 0.2148782082767907, 0.21449792680831764, 0.21411903555431286, 0.21373987171773948, 0.21335295777539742, 0.21296802943831902, 0.21258413125169418, 0.21220099924455058, 0.2118185794070143, 0.21143687157188024, 0.2108360816306859, 0.2104803582642839, 0.2100877870724889, 0.20969805773003403, 0.20931016069613667, 0.20892368340311812, 0.20853854725369875, 0.2081524136120593, 0.20776551962448458, 0.2073787449049579, 0.20699251400019825, 0.20660701596229475, 0.2062223261120515, 0.20583846491260888, 0.20545542672737557, 0.20507319387655157, 0.2046917434958519, 0.20431105087016987, 0.2039310910433732, 0.20355183958708103, 0.20317327296001458, 0.20279536866803877, 0.20241810532670623, 0.2020418219700983, 0.20166694408010094, 0.20129285341105646, 0.20091954699406747, 0.2005463075267356, 0.20017316011996633, 0.19980050734591223, 0.1994284587099747, 0.19905703147950565, 0.1986862138113751, 0.19831598513744908, 0.19794632289613995, 0.19757720478352148, 0.19720860950587124, 0.19684051701490723, 0.19647290855640143, 0.1961057666485022, 0.19573907503353588, 0.19537281862119757, 0.19500698343103245, 0.1946415565377921, 0.19427652602117707, 0.1939118809204039, 0.19354761119346858, 0.19318370768068605, 0.19282016207195926, 0.1922402382701077, 0.19191876145664935, 0.19154728753154468, 0.1911767041047918, 0.19080701570168127, 0.19043826412897732, 0.19007045509928863, 0.18970353683193386, 0.18933743838656605, 0.18897209340156568, 0.18860744815995806, 0.18824346170473238, 0.18788010321854426, 0.1875173491111244, 0.18715513817155002, 0.18679275904992101, 0.1864313060534052, 0.18607059678200005, 0.1857106148542487, 0.1853513406657134, 0.1849927542576993, 0.1846348363810774, 0.18427756895309177, 0.1839209352954944, 0.18356492024338772, 0.1832095101630587, 0.18285469290899484, 0.18250045774496773, 0.18214679524755056, 0.18179369720416522, 0.18144115651279516, 0.18089207000134389, 0.18057395378307914, 0.18021370664770242, 0.17985379633642942, 0.17949473083410267, 0.17913696979410193, 0.17878062332143455, 0.17842562277939186, 0.1780718490989319, 0.17771918859950872, 0.17736754939146113, 0.17701686165492017, 0.1766670730718553, 0.1763181438938221, 0.17597004302211777, 0.17562274525802282, 0.17527622949763147, 0.17493047758959615, 0.1745854736233297, 0.17424120348287292, 0.17389765455896422, 0.17355481555305466, 0.17321267633412454, 0.17287122782599376, 0.17253046191280014, 0.17219037135602938, 0.1716683562218576, 0.1713598560492644, 0.17101564461019667, 0.17067013842431603, 0.1703248230726729, 0.16998069663978307, 0.16963803183189918, 0.16929678932201686, 0.1689568451936255, 0.1686180782386359, 0.16828039308601492, 0.16794371998316282, 0.16760800852331853, 0.16727322142165604, 0.166939329898405, 0.16660631065156192, 0.1662741440026395, 0.16594281280429624, 0.16561230180645067, 0.16528259728390893, 0.16495368680726302, 0.16462555909005638, 0.1642982038760536, 0.16397161184795045, 0.16364577454831178, 0.16315627960762663, 0.1628568192062788, 0.162530790516321, 0.16220126254934922, 0.1618712240966571, 0.16154226427285537, 0.16121479928513832, 0.16088880025859592, 0.16056413024254013, 0.160240659576803, 0.1599182915853441, 0.15959695943161595, 0.15927661713564037, 0.15895723181680088, 0.1586387784485357, 0.1583212366998558, 0.15800458916253385, 0.15768882039926596, 0.1573739164423082, 0.15705986452464532, 0.15674665292493994, 0.15643427086561928, 0.15612270843504636, 0.15581195652082666, 0.15550200674899198, 0.1551928514272013, 0.15473797319049332, 0.15445206273386916, 0.15414728238505498, 0.15383563338309075, 0.153522676279122, 0.15321074763505174, 0.15290039206874448, 0.15259156698101345, 0.1522841121951114, 0.15197788780404473, 0.15167279625676355, 0.1513687734771638, 0.15106577656256337, 0.15076377477543967, 0.15046274413144656, 0.15016266448003956, 0.14986351803862882, 0.1495652886889825, 0.14926796164090553, 0.14897152325916796, 0.14867596095705207, 0.1483812631148016, 0.1480874190070381, 0.14779441873421723, 0.14750225315730767, 0.1472109138360558, 0.14679106099075626, 0.1465161452417795, 0.14623270373554215, 0.1459395842424637, 0.14564459131273727, 0.14535068719421984, 0.14505847330033925, 0.14476785568284994, 0.14447863495657257, 0.14419065543592524, 0.1439038172560116, 0.14361805898565558, 0.14333334103663045, 0.14304963514288493, 0.14276691873242586, 0.14248517223231594, 0.14220437788856705, 0.14192451928532385, 0.14164558115248296, 0.1413675492761471, 0.1410904104374987, 0.14081415235509773, 0.140538763625064, 0.1402642336599429, 0.13999055262829524, 0.13971771139667571, 0.13933517256272948, 0.1390721354369522, 0.13881058787361114, 0.13853674084362833, 0.13826058544903708, 0.13798560474237426, 0.13771239778826463, 0.13744080157171112, 0.13717057939754224, 0.13690156634880887, 0.13663366578780956, 0.1363668224914887, 0.13610100230166378, 0.13583416872620696, 0.13556810314216436, 0.1353051062938183, 0.1350444698020782, 0.13478572899875632, 0.13452866752204518, 0.13427313790560702, 0.13401902120544792, 0.13376621953245293, 0.13351465359383236, 0.13326425977840284, 0.1330149868474833, 0.13276679291432478, 0.13241893290001788, 0.13217573073404168, 0.1319440235293904, 0.1316972034627952, 0.1314475817130847, 0.13119926703062013, 0.13095284308918959, 0.13070805853260384, 0.13046463612418194, 0.13022240722496728, 0.1299815752772503, 0.12974203486004515, 0.12950352423572334, 0.12926597825260014, 0.1290293762926089, 0.12879370547538196, 0.12855895297827466, 0.12832510525676702, 0.1280921485134559, 0.12786006915240594, 0.12762885404365779, 0.12739849064400738, 0.12716896703538716, 0.12694027192155125, 0.1266314429718844, 0.1264011538687676, 0.12618809720596258, 0.1259590430491843, 0.12572795176949064, 0.12549852723060176, 0.12527092639690707, 0.1250447426252576, 0.12481969013516814, 0.1245956324040052, 0.1243725139257909, 0.12415031179156721, 0.1239290127796436, 0.12370860495091665, 0.12348907552498103, 0.12327041090755311, 0.12305259719750035, 0.12283562063602775, 0.12261946789398942, 0.12240412622373395, 0.12218958352264435, 0.12197582834564633, 0.12176284989053093, 0.12155063796990606, 0.12127076029812192, 0.12105280395007957, 0.12085851534015257, 0.12064564064452554, 0.12043063749660121, 0.12021750869694857, 0.12000625068568407, 0.11979635933693121, 0.11958752563305308, 0.11937961630988833, 0.11917258259109402, 0.11896640585632792, 0.11876107485017369, 0.11855657843915687, 0.11835290429692985, 0.11815003929445621, 0.1179479701086745, 0.11774668366544515, 0.11754616739213665, 0.11734640933664563, 0.11714739820734242, 0.11694912337036441, 0.11675157482551486, 0.11655474317237016, 0.11635861957269789, 0.11610426477407225, 0.11589831231810385, 0.11572263542318542, 0.11552542349068168, 0.11532602736603163, 0.11512878823941018, 0.11493348243076837, 0.11473949290525143, 0.11454648914327997, 0.1143543436963044, 0.1141630151695922, 0.11397248891329836, 0.11378275520605474, 0.11359380345538639, 0.11340562167574288, 0.1132181971591617, 0.1130315171254378, 0.1128455691313371, 0.1126603412814988, 0.11247582231648869, 0.11229200163329955, 0.1121088692712831, 0.11192641588157937, 0.11174463268955533, 0.11151352221356207, 0.11131905503066607, 0.11115985169543467, 0.11097660144495355, 0.11079125035359776, 0.11060834007494547, 0.11042739301188251, 0.11024770206874498, 0.1100689317299154, 0.10989096532280042, 0.10971376836378975, 0.10953732849808127, 0.10936163615729952, 0.10918668038818244, 0.10901244895403397, 0.1088389291238972, 0.1086661082762706, 0.10849397423943742, 0.10832251545063055, 0.10815172101188038, 0.10798158069176185, 0.10781208490047028, 0.10764322465278964, 0.107432325552407, 0.10724856083070826, 0.10710411902749192, 0.10693338691431216, 0.10676069710041064, 0.10659073241236845, 0.10642273436385989, 0.10625592350347941, 0.10608996974016895, 0.10592476909439212, 0.10576029298027134, 0.1055965302710164, 0.10543347103616757, 0.10527110382753072, 0.10510941617363133, 0.10494839536266845, 0.10478802895740741, 0.10462830506161319, 0.10446921243338708, 0.10431074051533182, 0.10415287942217599, 0.10399561990785965, 0.10380227607752339, 0.10362836309600464, 0.10349707606720326, 0.10333751588611989, 0.10317617964884858, 0.10301784994784159, 0.10286146608001474, 0.10270619457735614, 0.10255171905939436, 0.10239794880363343, 0.10224485989952765, 0.10209244166696632, 0.10194068362259166, 0.10178957391413626, 0.10163909998981507, 0.10148924929081288, 0.10134000966241853, 0.10119136955378034, 0.10104331809513495, 0.10089584510940877, 0.10074894109015703, 0.10060259716332608, 0.10042456547428208, 0.10025965008191426, 0.10014095700828972, 0.09999174069101464, 0.09984092308256348, 0.09969345842839562, 0.09954791817655301, 0.0994034137462319, 0.09925964486695338, 0.0991165334211801, 0.09897405917598479, 0.09883221157619645, 0.09869097973993349, 0.09855035170999796, 0.09841031513462058, 0.09827085782945388, 0.09813196809207413, 0.09799363485064447, 0.09785584771736501, 0.09771859698941504, 0.09755444757441284, 0.09739802774658954, 0.09728916033355198, 0.09714870504016511, 0.097006916485047, 0.09686869665048298, 0.0967323194202392, 0.09659689657863606, 0.09646215841245732, 0.09632803942941762, 0.09619452142874102, 0.09606159314487714, 0.09592924302864024, 0.09579745892706626, 0.09566622861567643, 0.09553554019674375, 0.0954053823208283, 0.09527574429182384, 0.09514661610124893, 0.0950179884207482, 0.09486552488604164, 0.09471645594756255, 0.09461741995270027, 0.09448504160962964, 0.09435153776678593, 0.0942219339548811, 0.0940941151374242, 0.09396717581126883, 0.09384087239569196, 0.09371514939912921, 0.09358998985278269, 0.09346538199619739, 0.09334131409196718, 0.09321777273806077, 0.09309457929645354, 0.09297164766017595, 0.09284905164953236, 0.09272682510883751, 0.09260498669684819, 0.09248354478916816, 0.09234100127140389, 0.09219868147801198, 0.0921082368112833, 0.09198268926382895, 0.0918560996392103, 0.09173363516945598, 0.09161278668923366, 0.09149266711016782, 0.09137307782618106, 0.09125398195341239, 0.0911353703540656, 0.09101723650927786, 0.09089957318739719, 0.09078237236652147, 0.09066562553408967, 0.09054932399569723, 0.0904334591258027, 0.09031802254413077, 0.09020300622452951, 0.09006993421797838, 0.0899339213644269, 0.08985028166369868, 0.08973092949079246, 0.08961081223396578, 0.08949504317409407, 0.08938078592444365, 0.08926719294973262, 0.08915410211978984, 0.08904148173525286, 0.0889293206483834, 0.08881761066005395, 0.08870634381446003, 0.08859551188089067, 0.08848510635844925, 0.08837511866024511, 0.08826554031705823, 0.08815636313524118, 0.08803154909197439, 0.0879012452508637, 0.08782364601792199, 0.08770982751775586, 0.08759548200997558, 0.08748568527026199, 0.08737728950802168, 0.08726949368801322, 0.08716217190792025, 0.08705529616283239, 0.08694885370834418, 0.0868428356534082, 0.08673723411889778, 0.0866320412142254, 0.08652724882729503, 0.0864228487468479, 0.08631883285583915, 0.08620125730608921, 0.08607617196747436, 0.08600371923979151, 0.08589482500705845, 0.08578562326882158, 0.08568112691610014, 0.08557791865818166, 0.08547525189124527, 0.08537303563158254, 0.08527124345697863, 0.0851698608155398, 0.08506887844524025, 0.08496828873636636, 0.08486808420047297, 0.08476825711831151, 0.08466879963682622, 0.08456970396675484, 0.08445844255236715, 0.0843377655909047, 0.08427079926244609, 0.08416639571626992, 0.08406187242446952, 0.08396234574385666, 0.083864013832807, 0.08376616805549511, 0.0836687513926411, 0.0835717367882312, 0.08347510765140657, 0.08337885483592611, 0.08328297137167943, 0.08318745039067725, 0.0830922846973266, 0.08299746687582363, 0.08289210501512426, 0.08277596902852813, 0.08271302345316227, 0.08261273759382465, 0.08251252633614906, 0.08241741996101215, 0.08232339466140726, 0.08222980489077716, 0.08213662737455503, 0.08204383312197014, 0.08195140356671018, 0.0818593298536002, 0.08176760556895743, 0.081676224297674, 0.0815851792126023, 0.08149446320878113, 0.08139427670664187, 0.08128109103184843, 0.08122345903502716, 0.08112692030228309, 0.08103055306191422, 0.08093962965887765, 0.08084967977660869, 0.08076010637343131, 0.080670929342644, 0.08058211675680578, 0.08049364790274874, 0.08040551475466103, 0.08031771174437882, 0.0802302330361609, 0.0801430722399588, 0.08005622259925298, 0.0799599292119159, 0.07984770385954595, 0.07979696825289699, 0.07970488955712847, 0.07961197018954294, 0.07952449028715669, 0.07943807819458307, 0.07935201093586976, 0.0792663250037228, 0.07918101073466126, 0.0790960402510634, 0.07901139714044147, 0.078927071544213, 0.07884305537986926, 0.07875934120736759, 0.07866725860474617, 0.07855900481862817, 0.07851081357169395, 0.07842282964572306, 0.07833266200654995, 0.07824862205793308, 0.07816569284397801, 0.07808298761984306, 0.07800065554311617, 0.07791869221692198, 0.07783705689278948, 0.07775573196504437, 0.07767470866937119, 0.07759397939621226, 0.07750607860728137, 0.07740167430679658, 0.07735537232764744, 0.07727035675592402, 0.07718339013346108, 0.0771024885405827, 0.0770225985799942, 0.07694288961836994, 0.07686354210619074, 0.07678454812352126, 0.0767058649933046, 0.07662747689744939, 0.07654937627451627, 0.07647155599128007, 0.07639400919191998, 0.07630972173350208, 0.07620738102735827, 0.07616554094897965, 0.07608313771953523, 0.07599879980374802, 0.0759210449857523, 0.07584425982351739, 0.0757675929658395, 0.0756912791143477, 0.0756153056960039, 0.07553962478935017, 0.0754642224133388, 0.07538909258398721, 0.07531422879290157, 0.07523362457539585, 0.0751348477955384, 0.07509458320689008, 0.07501486517202934, 0.07493343562168543, 0.07485850097932446, 0.07478444710834703, 0.07471047297579193, 0.07463684224108531, 0.07456353748788308, 0.07449050927142158, 0.07441774600422846, 0.07434524290723694, 0.07427299381263813, 0.07419563183551904, 0.07409942460694244, 0.07406179569908825, 0.07398443326921592, 0.07390548076678614, 0.07383321048905395, 0.07376176284900138, 0.07369034788879092, 0.0736192689560924, 0.07354850312307314, 0.07347799802098276, 0.07340774464368004, 0.07333773956202193, 0.07326342485916257, 0.07317052584155428, 0.073133786186438, 0.0730587751210246, 0.07298238346282786, 0.07291248120326942, 0.07284332839771772, 0.07277418150383197, 0.07270536133949712, 0.07263684072806613, 0.07256856730275214, 0.07250053456965863, 0.07243274000207525, 0.07236111692429752, 0.0722704375334165, 0.07223587556660552, 0.07216286176124542, 0.07208857646226662, 0.0720209208461193, 0.07195397174083612, 0.07188698880167214, 0.07182032577899239, 0.07175395047415668, 0.07168780871870052, 0.07162189678084635, 0.07155621324306102, 0.07148715267748945, 0.07139860740681948, 0.07136611589874577, 0.07129500107293713, 0.07122272593533424, 0.07115721465636446, 0.07109237154776112, 0.071027455714, 0.07096285296000782, 0.07089852616548975, 0.07083441981625145, 0.07077053312684661, 0.07070686569897502, 0.07064024687676322, 0.07055375996115498, 0.07052322950602376, 0.07045392256035568, 0.07038356893351458, 0.07032010462360554, 0.07025727499379755, 0.07019433483834049, 0.07013170057975537, 0.07006933052229936, 0.07000716840448962, 0.06994521651335332, 0.06988084844037544, 0.06979731023648313, 0.06976688800242893, 0.0696995372225151, 0.0696313173472456, 0.0695696628465123, 0.06950859641439625, 0.06944740983149847, 0.0693865177009301, 0.06932587720690991, 0.06926543503695892, 0.06920519551765325, 0.06914286260917388, 0.0690610886582094, 0.06903231643701598, 0.06896650584663377, 0.06889992373851561, 0.06883999876224328, 0.06878064240481616, 0.06872113516734912, 0.06866191387120511, 0.0686029332487342, 0.06854414072919175, 0.06848554328972417, 0.06842516109738571, 0.068345120860313, 0.06831788263566753, 0.06825355437705753, 0.06818855544579079, 0.06813028817207124, 0.06807257404407187, 0.06801468033687928, 0.06795706286651991, 0.06789967496421727, 0.06784246568708434, 0.067785444519938, 0.0677269307087336, 0.06764856971790492, 0.06762279157314394, 0.06755988298507752, 0.06749640591259112, 0.06743972759813165, 0.06738359148340312, 0.0673272488435331, 0.06727117130337974, 0.06721531208052657, 0.06715962281424939, 0.06710277201148221, 0.06702709442653883, 0.06700082093817797, 0.06693960574718996, 0.06687795713454323, 0.06682267431966361, 0.06676790602801783, 0.0667129395887077, 0.06665822262771913, 0.0666037126318576, 0.06654936724418856, 0.06649519854780031, 0.06644004910941609, 0.06636472052152417, 0.06634161552741595, 0.0662812505543368, 0.06622051297396982, 0.06616669890720196, 0.06611342081169858, 0.06605988978222974, 0.06600659697366493, 0.06595350033887995, 0.0659005596098901, 0.06584690880326925, 0.0657742363584682, 0.06575041252186929, 0.06569170337911875, 0.06563274135137581, 0.06558021299949476, 0.06552819739422722, 0.06547594604787545, 0.06542391418717175, 0.06537206739131043, 0.06532037313681432, 0.06526816568683277, 0.06519679158538898, 0.06517417944269246, 0.06511657143745911, 0.06505879528855037, 0.06500750876974852, 0.06495674138274284, 0.06490572203938133, 0.06485490443776498, 0.06480426114643205, 0.0647537660243304, 0.06470294720098232, 0.0646329184870793, 0.06461134321814838, 0.06455482823144121, 0.06449823179046055, 0.06444814079655778, 0.06439857648587005, 0.06434874933603982, 0.0642991033714756, 0.06424962078620153, 0.06420028325429365, 0.06415080215658636, 0.0640820781285458, 0.064061501783523, 0.06400603855660583, 0.06395058058872646, 0.06390164106188344, 0.0638532385020581, 0.06380456551907938, 0.06375605012467674, 0.06370768701433865, 0.06365946709261983, 0.06361127493635754, 0.06354382315404485, 0.06352419961897156, 0.0634697515057189, 0.06341539528398854, 0.06336756505234221, 0.06332028432744435, 0.06327272958185562, 0.06322530536235624, 0.06317802218279507, 0.06313086752319863, 0.0630657867178196, 0.06304505282600986, 0.06299206708404617, 0.06293922574661735, 0.06289236403953037, 0.06284603156495724, 0.06279946237356072, 0.06275300058149617, 0.06270667158035041, 0.06266060573302636, 0.06259650502286726, 0.0625767486459437, 0.06252459112910266, 0.062472647354323584, 0.06242672773479833, 0.0623813537783972, 0.062335744050578845, 0.062290211714928476, 0.06224480200886451, 0.06219978033369402, 0.06213676649063814, 0.06211775084126175, 0.06206645329613811, 0.062015435746610385, 0.061970427374745715, 0.06192597828361566, 0.06188130233784198, 0.06183667075894258, 0.061792151852029624, 0.06174814194454182, 0.06168617742875723, 0.06166789326979742, 0.061617423711836934, 0.061567299922078766, 0.06152317364535141, 0.06147962107953739, 0.06143585484104337, 0.061392095908958465, 0.061348439677978595, 0.06130540920422047, 0.06124447267482089, 0.061226888027934794, 0.06117722264235735, 0.061127967721585894, 0.06108469557305223, 0.061042011541457324, 0.060999132204144546, 0.06095621878317914, 0.060913398161309446, 0.06087131628381424, 0.060811385678163854, 0.060794472336714006, 0.060745587587539895, 0.06069717681856379, 0.06065473204299944, 0.06061288939892452, 0.060570875471971264, 0.06052878130907163, 0.06048677016442823, 0.060445607323317024, 0.060386661619084195, 0.06037039227116874, 0.0603222657107164, 0.06027467529358434, 0.060233032317168284, 0.06019200464112853, 0.06015083591102241, 0.06010953558884195, 0.06006830869170376, 0.06002803658240758, 0.05997005554367077, 0.05995440406772022, 0.0599070141823742, 0.05986022108837551, 0.0598193554891312, 0.059779117037759066, 0.05973877454128168, 0.05969824342337879, 0.05965777640048037, 0.05961836792737421, 0.05956133208435045, 0.05954627347058525, 0.059499599644786516, 0.05945358157722865, 0.05941347005589726, 0.059373995704085775, 0.05933446170019864, 0.05929467587800577, 0.059255752051613396, 0.05920080067640759, 0.05918416781617121, 0.059138836782392734, 0.059094093187440376, 0.059054647383900705, 0.05901579094547427, 0.05897693576016476, 0.05893781091206506, 0.05889963504678452, 0.05884530010646786, 0.05882948236633181, 0.05878467193618383, 0.058740504915372777, 0.05870170141326909, 0.05866349989993179, 0.05862534620201285, 0.05858685396932936, 0.05854936244090469, 0.05849585274042313, 0.05848046615619508, 0.05843628361428968, 0.058392778606433215, 0.058354602065808225, 0.05831702823078801, 0.05827955760965394, 0.05824168204123834, 0.058204861763560094, 0.05815212856004282, 0.05813721403578249, 0.05809362555411023, 0.05805075001501565, 0.058013184359166615, 0.05797622098550292, 0.057939423133231305, 0.057902146573441594, 0.05786597658459022, 0.05781401216266558, 0.057799544112661236, 0.05775653940413422, 0.05771428006268267, 0.05767731015208107, 0.05764093880255089, 0.05760480282957504, 0.05756810838345549, 0.05753256974670707, 0.05748136037665237, 0.0574673246500877, 0.05742489024061376, 0.05738323113663642, 0.05734684243359736, 0.05731104521803343, 0.05727556124283587, 0.0572394323087139, 0.05720450636588707, 0.05715403989124871, 0.05714042109296235, 0.057098544742298404, 0.057057470787289497, 0.05702164940084025, 0.05698640867394952, 0.05695156751168984, 0.05691598784184193, 0.05688165649686215, 0.05683192104543044, 0.05681870464742475, 0.05677737458441288, 0.056736870928212106, 0.05670160358166389, 0.05666690197361886, 0.056632695177005296, 0.05659764883766641, 0.05656389447269113, 0.056514878658191076, 0.056502050605631515, 0.056461255662783344, 0.05642130777267691, 0.0563865817841586, 0.056352402177920764, 0.05631882200785816, 0.05628429335922481, 0.05625109881744827, 0.05620279168491031, 0.056190338433038375, 0.05615006802781457, 0.05611066164371923, 0.056076464903280734, 0.056042790424104455, 0.0560098298323828, 0.05597580350623217, 0.05594315206153305, 0.05589554307874759, 0.05588345155092543, 0.0558436957009429, 0.05580481681303616, 0.05577113775973957, 0.05573795176659915, 0.055705604374261725, 0.0556720652541575, 0.05563994058275075, 0.055593019623673454, 0.055581277182580865, 0.055542026520688466, 0.055503661342916955, 0.055470488941152564, 0.05543777502242199, 0.055406035096721595, 0.05537422007541576, 0.055328716644180695, 0.05531506504200933, 0.055277096087229936, 0.05523987813334407, 0.055207184850236686, 0.055174827344412744, 0.05514348120262824, 0.055112197278814154, 0.055067004544393505, 0.05505415208671011, 0.05501642209458698, 0.05497950371662586, 0.05494724183067612, 0.05491528470843183, 0.05488449369400883, 0.054853617410661595, 0.0548090198662175, 0.05479634821321254, 0.0547590855468714, 0.0547226405354329, 0.05469080795818859, 0.05465922930938055, 0.05462895005931268, 0.05459849570631317, 0.054554418372490684, 0.05454206048436386, 0.054505200547581324, 0.05446917825573005, 0.05443776638739374, 0.05440655520201724, 0.05437679486934288, 0.054346743211949926, 0.05430319321593887, 0.05429110892317567, 0.054254655820473216, 0.054219058880348926, 0.05418806100000115, 0.054157204041530294, 0.054127957668058134, 0.05409829788298469, 0.05405526354498555, 0.054043454397215716, 0.05400739554993437, 0.05397221430873293, 0.05394162359203682, 0.053911108105736724, 0.05388237447632631, 0.05385309357104203, 0.053810568106954386, 0.053799026018762214, 0.053763352763378576, 0.053728581231553656, 0.05369839118841639, 0.053668204335452996, 0.0536399818857867, 0.05361106737548258, 0.05356904320258195, 0.05355776310364547, 0.053522465488182756, 0.05348809740108475, 0.05345830174769814, 0.053428430710885655, 0.05340071863296983, 0.05337215776616712, 0.0533306279322731, 0.05331960460518066, 0.05328467263291198, 0.053250702512915214, 0.05322129517158075, 0.05319172712646995, 0.053164525089177544, 0.0531363049811374, 0.053095262828219525, 0.05308449176299959, 0.05304991497290574, 0.05301633790743081, 0.05298731297229928, 0.0529580350857029, 0.05293134334037286, 0.05290345084469379, 0.05286289013010476, 0.05285236733575487, 0.05281813481323454, 0.052784946582785895, 0.05275629828821515, 0.05272729771480092, 0.05270111709978102, 0.05267353873735675, 0.052633453642500265, 0.052623175745474246, 0.05258927600668667, 0.05255647312670659, 0.05252819580838696, 0.05249945969109285, 0.05247379167434183, 0.05244651352602675, 0.052406898704221536, 0.05239686297601386, 0.05236328387683435, 0.05233086367488028, 0.05230295172388308, 0.052274467198934124, 0.05224931392016062, 0.05222232150611407, 0.05218317212977207, 0.052173376544459235, 0.052140105170883515, 0.05210806586612893, 0.05208051367315477, 0.05205226788110252, 0.052029248460607205, 0.05199048508838452, 0.05197845914176266, 0.05194696742808952, 0.05191506262150769, 0.051888281634041175, 0.051860285807123346, 0.05183556373258319, 0.05180935207014656, 0.05177113691531327, 0.051761549113494475, 0.05172897373458703, 0.051697619951353885, 0.05167078486724534, 0.05164296151252707, 0.05162095865670491, 0.051582766166983755, 0.05157119558829012, 0.051540423260924374, 0.05150895909889755, 0.05148296223480613, 0.05145535683875737, 0.05143153267746323, 0.05140585117516181, 0.05136849537192564, 0.051359206991980766, 0.051327206520881394, 0.051296581551157676, 0.05127041731510505, 0.051242962648853294, 0.05122202066247441, 0.051184348466796134, 0.051173188980247794, 0.05114314390497087, 0.05111206616305536, 0.05108688087733124, 0.051059607275080764, 0.05103667549260602, 0.05101150385926012, 0.05097497789747077, 0.05096598603322359, 0.05093450717283842, 0.050904614446935004, 0.05087911669228599, 0.05085198023687745, 0.050832129193779434, 0.050794916946878016, 0.050784158375270304, 0.05075484212423461, 0.0507240805190644, 0.05069974000673192, 0.05067273491005631, 0.05065069610293361, 0.0506260153204577, 0.05059029301366894, 0.05058154841711962, 0.05055060033351032, 0.05052149794236987, 0.05049655292411238, 0.050469687300339114, 0.05045104720593884, 0.05041419857882384, 0.05040366230492301, 0.05037536086093392, 0.0503450295581582, 0.05032105900076619, 0.050294273627472255, 0.050273497422992454, 0.05024921733489214, 0.05021414144448348, 0.0502055203560013, 0.050175214674601835, 0.05014694158955421, 0.05012241295138187, 0.05009582903225758, 0.05007812024767819, 0.05004197570323432, 0.05003168379633715, 0.050004234245078286, 0.049973869471810595, 0.049950812073816644, 0.04992443780303472, 0.04990556280392747, 0.04987128537525183, 0.04985986652912734, 0.049833476956537594, 0.04980354099943069, 0.049780451932728696, 0.04975487469129926, 0.049733572826196566, 0.049710344911919446, 0.04968582605801746, 0.049652467756503824, 0.04964523523994939, 0.04961767237770699, 0.04958762555140423, 0.04956305154980313, 0.049538826511209534, 0.04951845007913197, 0.0494967006424517, 0.0494623659770412, 0.04945373802848837, 0.049426319635445595, 0.04939668521131294, 0.04937396985534622, 0.04934969910379789, 0.04932858592277509, 0.0493074555727899, 0.04927339270095841, 0.049265594120742356, 0.04923929532195626, 0.04920858603290173, 0.04918524078244398, 0.04916257475774014, 0.04914320525236015, 0.04911126347151512, 0.04910124150557566, 0.049075738250965326, 0.04904566734419041, 0.04902265256915838, 0.0490006788269586, 0.04897971854354921, 0.048958788029017375, 0.048924991966052246, 0.04891704357078328, 0.04889285636617224, 0.04886210079645686, 0.04883839469094554, 0.048816614341459674, 0.048798310160922155, 0.0487666595422521, 0.048757131805677534, 0.048732207460270675, 0.048702180463083306, 0.04867953927025093, 0.048658198610732645, 0.04863818427383158, 0.048617530419630434, 0.04858423590858322, 0.048575773364654726, 0.048552753026557954, 0.04852291912007166, 0.04849958478985457, 0.048477877955298176, 0.04845866294901578, 0.04843914984984306, 0.048405506874494776, 0.048397963785155686, 0.04837489468921028, 0.048344585832524836, 0.048321643970446075, 0.0483001685462712, 0.048281405341984926, 0.04826206613228161, 0.04822881222650763, 0.048220662467405855, 0.04819822968382699, 0.048168554292631754, 0.04814596399362013, 0.04812454475074925, 0.048105902215526915, 0.04808690168130131, 0.04805402529247584, 0.04804618101300049, 0.048024015466024944, 0.04799427053539654, 0.04797198920703144, 0.04795078886899145, 0.04793249299670276, 0.047913769015225136, 0.04788114467198253, 0.04787328344635572, 0.04785154785497494, 0.04782198702728131, 0.04780001408800705, 0.04777893575411281, 0.04776090341588423, 0.04774249176072136, 0.04771016650698583, 0.0477023881601012, 0.047681009620317266, 0.04765153694433841, 0.04762988308556826, 0.04760895390220787, 0.047591203180427644, 0.047573082482261095, 0.047541037395587904, 0.047533305210243876, 0.04751230431755034, 0.04748294398887191, 0.04746160616545715, 0.04744080794969424, 0.04742332673642958, 0.04740550305473804, 0.04737373651053184, 0.047366068300430726, 0.047345430820873786, 0.04731615858691886, 0.04729514001104553, 0.047274470518624157, 0.04725725907276167, 0.04723972805202074, 0.04720823235109787, 0.04720062045375454, 0.04718034717893987, 0.04715116183427676, 0.047130464042423534, 0.047109914077919646, 0.047092966394014044, 0.04707572809799442, 0.047044498937794936, 0.0470369476168709, 0.047017033051936524, 0.04698792277451198, 0.04696754840126848, 0.04694711190878293, 0.04693042500331515, 0.04691347782280055, 0.04688250893036955, 0.04687501770578115, 0.046855459469733546, 0.046826417227690084, 0.04680636876741951, 0.04678603804673561, 0.046769607671702296, 0.046752951064243084, 0.0467222369247471, 0.04671480797509735, 0.046695602384447144, 0.04666661892519886, 0.04664689943040154, 0.046626667366359474, 0.04661048991115156, 0.04659412303605895, 0.04656365758352859, 0.04655629256861181, 0.04653743655186096, 0.04650850356048891, 0.04648911627777299, 0.04646897531935677, 0.04645304698673058, 0.046436969320791596, 0.046406746490336714, 0.04639944814870814, 0.04638093828138503, 0.04635204681216678, 0.046332995373535385, 0.046312937998839426, 0.046297255234064465, 0.04628146624037303, 0.046251479640037625, 0.046244251111635055, 0.04622608401763429, 0.04619722523806354, 0.046178513572649876, 0.046158532042760006, 0.04614309135828741, 0.04612759060894509, 0.046097833634087114, 0.04609067889086329, 0.04607285099679596, 0.04604401578143938, 0.04602564816807782, 0.04600573462655077, 0.04599053273626454, 0.04597314444403411, 0.04595280937556521, 0.045926043494524296, 0.04592083390797198, 0.045904362735846, 0.04587403669911214, 0.045854163759088504, 0.04583525090522352, 0.04582389297616281, 0.04579860485964213, 0.04579024076056284, 0.04577091447715777, 0.04574030359723396, 0.045724343612497234, 0.04570643820829006, 0.04569083755205355, 0.045672638627649406, 0.045650023208075576, 0.04563182077690006, 0.04561701870899444, 0.045592442848556486, 0.04558897723356557, 0.04556627097385742, 0.04553921221486667, 0.04552022068735319, 0.0455022766164207, 0.04548740414177619, 0.045470414077034615, 0.045448672203128176, 0.04543101707548551, 0.045408081606678016, 0.04540399912726022, 0.04538685489358004, 0.04535510874230386, 0.04533687705965079, 0.04531977392092499, 0.04530998432679741, 0.045284752929184914, 0.04527629019289163, 0.04525772733465994, 0.045227924620834206, 0.04521275815879856, 0.045194802066778186, 0.04517933620109606, 0.04516269501146776, 0.04514056202289228, 0.045122958944834195, 0.04510823446725777, 0.045084880743029826, 0.04508121988954941, 0.04506041694229643, 0.04503298151907872, 0.045015407009359534, 0.044997994460660065, 0.04498392848367451, 0.044969799589595155, 0.044941970239297094, 0.044934402614589496, 0.044920053749290846, 0.044891889955797015, 0.04487597075210957, 0.044856400195912666, 0.0448426063336447, 0.04483004247606465, 0.04480215520828098, 0.04479640694937725, 0.044781324575320254, 0.04475135866345737, 0.044736507494588545, 0.04471703787796734, 0.0447038289587562, 0.04469118399063955, 0.0446629729577272, 0.04465666352786053, 0.04464221070806079, 0.04461332391055936, 0.044598743388012625, 0.044578972578364295, 0.0445657422600242, 0.04455350368384013, 0.044525777454835165, 0.04452021931588249, 0.04450571210034755, 0.04447609776045733, 0.044461965865064165, 0.04444237162090622, 0.04442952615107145, 0.044415427484536585, 0.04439511555612537, 0.04437453413810692, 0.044366126913180745, 0.04435709242017091, 0.04432641379085434, 0.04430840894121873, 0.04428870224392352, 0.044279101938919714, 0.04426387941756248, 0.04424989173542251, 0.04423345412541815, 0.04420645900094327, 0.04419250977823599, 0.04417563711538266, 0.04415880521666856, 0.04414563529834667, 0.04412512525484932, 0.044108610877996904, 0.044094756468287324, 0.044083551980108514, 0.04406514729052495, 0.04405354553515477, 0.04403526272591779, 0.04401428919238561, 0.043989403795249585, 0.04397148551479897, 0.04397015758552967, 0.04396341941474068, 0.04393405875341936, 0.043917171897444644, 0.043907941761700195, 0.04388810670506397, 0.04386011654245399, 0.043838190768641996, 0.04383492327872215, 0.04382746682876956, 0.04381801165679605, 0.043785124610946254, 0.04377786861359873, 0.04376727914757005, 0.043746019774616896, 0.04372100692593341, 0.04369354990412211, 0.043707471213642206, 0.043696011802120203, 0.04369075548613849, 0.04364432149048465, 0.043644387198172915, 0.043654427202072764, 0.04359248527543709, 0.043598053656166626, 0.04356245603743502, 0.04356642719006225, 0.04354985954708651, 0.04352206916557774, 0.043516318029605226, 0.04349115062427966, 0.043512137802829955, 0.04347628259499715, 0.04344101064695979, 0.04347259173075377, 0.04343792055782394, 0.04345992994784195, 0.043433410908882614, 0.04343950175477631, 0.0433796209276664, 0.043415870568371005, 0.04336728577969463, 0.04331369499731225, 0.04332082537308774, 0.043272549985573755, 0.043267707201885414, 0.04328343375979483, 0.043231889142703685, 0.04323112094824128, 0.04318731205321294, 0.04320261963354559, 0.04318002551123566, 0.04314054697739197, 0.043163780843865796, 0.04311732153377174, 0.04312636782130489, 0.043115846753926546, 0.04306170393685256, 0.043092721802841016, 0.043048470595808234, 0.04305230532849765, 0.043067560811788815, 0.04298650596425849, 0.04303945080139347, 0.042979138832559764, 0.04297475748650558, 0.04303679382503258, 0.04291405211887938, 0.042948124307905185, 0.0429026584449951, 0.04287847676532653, 0.04291333493289576, 0.04283842734164775, 0.042835271882755765, 0.04280404386363716, 0.04281527980600539, 0.04277496886783385, 0.042790730955665775, 0.04275420105386883, 0.04275028175992903, 0.04272820929158721, 0.04271775100927211, 0.04274829390291329, 0.04271368396456885, 0.042868259221376645, 0.04272375051423582, 0.042709665983220395, 0.04270365549096724, 0.04280110656929713, 0.042640352386766035, 0.0426672598343546, 0.04272492342723546, 0.042562618198730626, 0.042593943506153295, 0.042593091081974774, 0.04252639373204116, 0.04254090609216678, 0.042549603635509504, 0.0424815616674329, 0.04255221756008533, 0.042452650094232235, 0.04246246933445927, 0.04256915192639355, 0.04239847706180967, 0.04249844111485734, 0.042416231181597486, 0.04241929095395125, 0.04248043382881817, 0.042344696308934934, 0.042302968337591826, 0.04230902108491914, 0.042296606093456375, 0.04227617760487114, 0.04224864903948922, 0.04226838713887141, 0.04223419109940265, 0.042205701628636565, 0.042268600635168754, 0.04221208297195346, 0.04220808569731488, 0.04227800691626962, 0.04214786364505196, 0.04226448117100965, 0.04216938125733785, 0.04221808543167228, 0.04229336862734108, 0.04208755631369925, 0.042062661116253244, 0.04207528153248396, 0.04203138008332672, 0.04208513689441694, 0.042022641626849065, 0.042010669563063235, 0.042063426355320024, 0.041963001397860605, 0.04198119132069562, 0.04196368158720671, 0.04192653759909407, 0.04193225713448139, 0.04191729028836436, 0.04186598412432636, 0.041897067816735675, 0.04185271173539636, 0.04184509760805693, 0.041866453353467746, 0.041797607570575546, 0.041816733828513725, 0.04177793376580989, 0.04178962412622976, 0.04175827775125522, 0.0417284935774887, 0.04175327613919709, 0.041700726936782985, 0.04170134203504633, 0.04168774237803268, 0.04166002659284787, 0.041688818083799054, 0.041636542071690784, 0.04163597161882602, 0.0416169833571758, 0.04161274962884921, 0.041583809974468054, 0.04158556702232124, 0.04157668978528348, 0.041543658835687086, 0.04155487366992405, 0.04152425511502199, 0.041552666917788465, 0.04149589444149019, 0.04148063165613025, 0.04147488746326614, 0.041452253748278205, 0.04147173936491363, 0.041425595153833525, 0.04142535522428564, 0.04141406979858452, 0.041394715931996215, 0.0414541130726029, 0.041743574184311356, 0.04145650282855759, 0.041438317364943425, 0.04150243090398513, 0.04173467697518809, 0.041400830190320544, 0.0414584065266291, 0.04147285947562905, 0.04132217010729396, 0.04138084272102822, 0.041543197397061575, 0.04126919560640193, 0.041360294029060655, 0.04147323102482525, 0.04129097076871638, 0.04135457439286112, 0.041523172856338345, 0.041217627579840155, 0.04125135299650743, 0.041364813478119974, 0.04117942777150508, 0.041209079259328645, 0.041496444953061186, 0.04112225627160075, 0.041159950853415214, 0.041093734529079384, 0.04105708186660682, 0.04107941408957508, 0.0410826556177961, 0.04101465059117978, 0.04102097586635462, 0.0411005405250356, 0.04096694942225823, 0.040986613266563075, 0.040941184243037394, 0.04091786049841247, 0.040916476407816676, 0.0409033028157592, 0.04089140535382869, 0.04085726392133274, 0.040876293913592564, 0.04083956814357686, 0.04083412190112216, 0.04082189139067826, 0.04079306283714893, 0.040815803034206274, 0.040775414003833665, 0.04076943541976459, 0.04076392673650272, 0.04073492324019949, 0.04075160992840974, 0.04071651370041973, 0.04071306094134967, 0.040707958865965566, 0.04067906796539729, 0.040692489421862446, 0.04065371439238903, 0.04064285666143184, 0.04064020095389649, 0.040608046944097025, 0.040621293294834444, 0.04058966390331194, 0.04058054864886349, 0.04058953284584081, 0.04056042820006453, 0.040580430104649935, 0.04053920818127758, 0.040521957796195364, 0.040557508879309374, 0.04051281453959939, 0.040502107198850106, 0.040533216064833545, 0.040464797322878165, 0.0405057118533229, 0.040466600505255565, 0.04046871676569167, 0.0404731336008275, 0.04041326080095102, 0.04039768326636336, 0.04037506279065534, 0.04037682467591319, 0.0403836276995097, 0.04035415282123403, 0.04036528971777459, 0.040332027400267235, 0.04031565987993502, 0.040322648282389746, 0.040286500523185574, 0.04026859274093133, 0.0402837300061725, 0.04024476451233125, 0.04024032087274462, 0.040230662930934906, 0.040210033352018906, 0.040207682780191156, 0.040191117369777644, 0.04017390024560656, 0.04017891644163571, 0.040149146191922114, 0.040158660982537245, 0.0401269020795647, 0.04012205534970293, 0.04010913670831961, 0.04010012622224467, 0.04008808444786797, 0.040073649950425484, 0.04006606296729299, 0.040050843851132424, 0.04004565719900984, 0.040029548691769945, 0.0400186471498245, 0.04000938852776601, 0.0399937558648513, 0.039990536808118725, 0.03997223706048314, 0.03996320647464031, 0.03995369118359115, 0.03993687586225602, 0.039934737509007834, 0.03991768985159313, 0.03990822873913542, 0.03989892717611751, 0.03988124918365112, 0.039883575778207093, 0.03986196101936229, 0.03985784557971307, 0.03984582748401118, 0.03982759079827401, 0.03983893400181839, 0.040207441272067636, 0.0399382227869557, 0.039898901671177135, 0.040022312088464074, 0.040329772001610635, 0.0398985987863044, 0.040092041344472265, 0.03982472171443074, 0.03989760957535866, 0.04004396244593736, 0.03977393868920553, 0.039946050774435526, 0.040172787930956154, 0.03987501440247418, 0.03996462007799705, 0.03990133768990812, 0.04007424246411272, 0.04002134292957111, 0.04022064247266864, 0.03987923073156716, 0.0399437222224884, 0.03968291570097316, 0.03971651763013682, 0.039824251990026614, 0.03977291651300163, 0.039856886483275795, 0.03982376303914453, 0.04010097854413578, 0.039913170860537736, 0.039775420205719586, 0.039674540332557615, 0.03993304995564025, 0.03987587537903696, 0.0399098733944976, 0.0398583061969474, 0.039808696927111344, 0.03986008050973755, 0.039664111851593714, 0.03969456456020928, 0.03966317258274084, 0.039663608444031426, 0.03958121947318412, 0.03998150220172286, 0.03967301535776581, 0.0396077000560859, 0.03944765184964142, 0.0395457690845486, 0.03974372372980684, 0.03934235510882428, 0.03931779951420619, 0.03929639387822378, 0.039342223669389366, 0.03926458029295826, 0.039263943645337404, 0.039375393346703515, 0.03924818548139272, 0.03928166695511252, 0.039458126042614276, 0.03931924893184574, 0.039258432022915686, 0.039621681557966346, 0.03929308778399769, 0.03933021632027652, 0.03923189061451288, 0.0393318465994889, 0.03935936166995151, 0.03927382408320769, 0.03934975416504587, 0.039243925229341774, 0.039587009073001694, 0.039359488959208766, 0.03925581996607434, 0.03926382497552888, 0.03973733316324494, 0.03950930330352599, 0.0395565845735164, 0.03920292535116087, 0.03931890519182028, 0.03904632052613636, 0.03903855082427553, 0.039059627726499166, 0.039089811797620395, 0.03900878848665189, 0.039068352077728206, 0.03930463598976534, 0.039213569127494276, 0.03913211591681291, 0.039308671833011954, 0.03928450205823103, 0.03954525744764512, 0.03963022765907499, 0.03955344046900155, 0.03923541068325669, 0.039289375269675963, 0.039337660797743416, 0.039421147105132455, 0.039578307086756, 0.03935869445854795, 0.03950241036946884, 0.03921413990993176, 0.03911829590410381, 0.039180057978512726, 0.03925230423566623, 0.03950436207367928, 0.03929958663772896, 0.0392515091296756, 0.03885476846566209, 0.0388072921877813, 0.038774291127598906, 0.03890152885051661, 0.03883248126484274, 0.03901282451077771, 0.03906596686393405, 0.03907025835855418, 0.03881367801240154, 0.03892045882246306, 0.03890968470881013, 0.03894125486890327, 0.038899311862906766, 0.03890571763604677, 0.03884300610738488, 0.03878756346740665, 0.0387551332150049, 0.03871100583976688, 0.03870633454778107, 0.038635553396688914, 0.0386212368336447, 0.03860125655291309, 0.038561233282270554, 0.038546471039151965, 0.03853613189950131, 0.038506096092309774, 0.038496114152523936, 0.038486037914229776, 0.038464413250314806, 0.03845435646374976, 0.038445549552053995, 0.03842750729324847, 0.0384182585114976, 0.038409067983594745, 0.0383937610011986, 0.03838440076429524, 0.03837572525218223, 0.03836487181297646, 0.038352995489415564, 0.03834206745627282, 0.03833292725968773, 0.03832298854683101, 0.03831230376286654, 0.03830191922786317, 0.03829252173274487, 0.038282829796154126, 0.03827264130241132, 0.038262568318635275, 0.03825300089541394, 0.038243336446454605, 0.03823336892265701, 0.03822345291702395, 0.0382137928308771, 0.03820410464359544, 0.03819424422105982, 0.03818440861491131, 0.038174705822358275, 0.038164997440664115, 0.03815519699672209, 0.03814541002499846, 0.038135695422165536, 0.03812598294188584, 0.03811622448075263, 0.038106475378121805, 0.038096768527763974, 0.03808706711584208, 0.03807734527113571, 0.03806763188082023, 0.03805794548363618, 0.03804826641311157, 0.03803858086518723, 0.03802890404740152, 0.03801924640292746, 0.038009597319129125, 0.03799994937690165, 0.03799031071176332, 0.03798068718681684, 0.03797107303665138, 0.03796146421541322, 0.03795186515544693, 0.03794227914183848, 0.037932703017957786, 0.03792313454035565, 0.03791357616402517, 0.03790402973083145, 0.03789449349243381, 0.03788496618378034, 0.03787544918200616, 0.037865943522426344, 0.037856448220588375, 0.03784696255065197, 0.03783748729131887, 0.03783066129463328, 0.037830789406359956, 0.03781094707132455, 0.03782376145538698, 0.037787076662346555, 0.03777957022120832, 0.03776676744474296, 0.037769091476097305, 0.037745997625481836, 0.03775254163961745, 0.03773071378091267, 0.03771894351221076, 0.03771028636444339, 0.037710631264205555, 0.037689231980197795, 0.037698877911979845, 0.03766897189773552, 0.037672338878576336, 0.037653753305972336, 0.03764864469380685, 0.03763325114552782, 0.03763945904780242, 0.03761618405830183, 0.03761713000289667, 0.03759408871769545, 0.03759994569733417, 0.037581540220493766, 0.03757824048264227, 0.037559145040202906, 0.03756223014942427, 0.03754836243487933, 0.03754035531276982, 0.03753172867041269, 0.03752095913156, 0.03750820240174944, 0.03750389649678346, 0.037489186760089645, 0.037482329947539916, 0.03747470116747937, 0.037463627250868686, 0.03746062481412867, 0.03744497177110129, 0.03743445963084539, 0.0374339772777831, 0.037417972295500285, 0.03742614792695031, 0.03739763720234495, 0.037394000269376254, 0.03738414755128293, 0.037378687030647874, 0.03736857282690721, 0.03736532913846093, 0.037345872838315926, 0.03734962379520436, 0.0373285215402137, 0.03734111088111994, 0.037312812702494355, 0.03732218132012935, 0.03729663429594154, 0.03730643168522592, 0.037284529190580694, 0.037285830010227554, 0.037267444251715916, 0.03725323343614561, 0.03724762466424748, 0.03723296746078377, 0.037231966009367845, 0.03721733176750193, 0.037219843884241675, 0.037202689511064466, 0.03719392985456003, 0.037182409575161314, 0.03718465122569077, 0.037161412294015345, 0.037160988097635864, 0.037149811871339956, 0.03714442592013976, 0.03713687053136612, 0.0371249169377836, 0.037110468599408634, 0.03711389087710935, 0.03709337559901194, 0.0370899092594701, 0.037082258579145475, 0.0370683876741761, 0.03707628070578613, 0.037051307708152924, 0.03705869560877089, 0.037037834318903666, 0.03704178351344253, 0.03702797663885973, 0.0370266168583217, 0.03707357909345863, 0.03728477808016646, 0.037065744758324394, 0.03707393235104641, 0.037092910763035135, 0.037135715148902834, 0.03730155814260179, 0.037552474527655415, 0.037429469566082466, 0.03760036672653274, 0.03733268492520005, 0.03740517779051073, 0.037238427411470196, 0.03746357637029437, 0.037500694532167866, 0.037199726930559736, 0.03738796527485041, 0.037380945147389516, 0.03751414465445254, 0.037393004583185396, 0.03727916582076736, 0.036948354207890194, 0.037194514943647616, 0.03707711872429747, 0.03725066288175791, 0.03733820760695621, 0.03738709985209699, 0.03725655834010062, 0.03716285691226957, 0.03710475832360146, 0.03704859272259616, 0.037034099166943044, 0.03696021454463036, 0.03694869857017609, 0.036872588548865305, 0.03684283475485364, 0.03681873207539295, 0.036761437100390586, 0.03677187110006806, 0.03672065194442231, 0.036717664098876626, 0.036699911581375574, 0.03668433809187022, 0.03666010781261293, 0.03666620024395011, 0.03663831857639048, 0.036632692655035284, 0.03662709790160781, 0.036611296848889495, 0.03659754967256327, 0.03659970050094284, 0.03657865326058637, 0.036572066895384836, 0.036569185554981856, 0.036552484502501495, 0.03654323283149813, 0.036542618182772074, 0.03652382352045841, 0.03651775585910901, 0.03651468656376231, 0.03649760303483397, 0.03649221288430479, 0.03648710268959205, 0.036474186414297116, 0.036467347014634235, 0.03645746877762536, 0.036450320518117, 0.03644086699209409, 0.03643225820690288, 0.03642383467687001, 0.036415962580126714, 0.036406927750280926, 0.036398348883588054, 0.03638997403933264, 0.03638184436928057, 0.03637308849995585, 0.036364516073300636, 0.03635619027374571, 0.03634792477525955, 0.03633936572309975, 0.036330851002105355, 0.03632255507478567, 0.036314228325541535, 0.03630576955671777, 0.03629730164293342, 0.03628900681885553, 0.036280662362792516, 0.03627225772388641, 0.03626383784672076, 0.036255539504109396, 0.036247202314233284, 0.03623883289078317, 0.03623045825868806, 0.03622216172283905, 0.036213843563801716, 0.03620550387119891, 0.03619716983032266, 0.03618888331614165, 0.03618058906844722, 0.036172278973764516, 0.03616398119092797, 0.03615571218440488, 0.03614744387170142, 0.036139164599996526, 0.036130900037203074, 0.036122654055045895, 0.03611441280250636, 0.036106165380778606, 0.036097932349286696, 0.036089712947208266, 0.03608149969190326, 0.03607328459597438, 0.03606508239891621, 0.03605689164589355, 0.03604870727071781, 0.036040524534017876, 0.036032353045298796, 0.03602419204682132, 0.03601603732803113, 0.03600788674628185, 0.03599974608295632, 0.035991615388845544, 0.035983490931633465, 0.03597537222341078, 0.03596726254548595, 0.03595916241396616, 0.03595106862827359, 0.035942981523545386, 0.03593490293855522, 0.03592683348422637, 0.03591877059914914, 0.03591071487110289, 0.03590312899465904, 0.03590408568482909, 0.035894847982943304, 0.03590730178284221, 0.03588328015252299, 0.035881631178687035, 0.03585742855032911, 0.035885816161939345, 0.035896889011894854, 0.035866341824055285, 0.036017039521383895, 0.035985550937913384, 0.035907727558087056, 0.035926715355064476, 0.03602056495146772, 0.03590844337603821, 0.035965914461820556, 0.03587639880764167, 0.03590219798703405, 0.0358811666595629, 0.035829124838231044, 0.035883391530749965, 0.03581425895937021, 0.03581459426312859, 0.0358167270175899, 0.035805078756980906, 0.03576888146879056, 0.03580076725070461, 0.0357642295446373, 0.03575266689216324, 0.03576883872503267, 0.035743455024747295, 0.03572370188925766, 0.03574641013765658, 0.03570578045876519, 0.03571347547311032, 0.035710902577699835, 0.0356847875333039, 0.03568066353757867, 0.03568927309888326, 0.03566340899452012, 0.03565838535425038, 0.03565705599482044, 0.035641848150079106, 0.035632321230511244, 0.035630706781574734, 0.03561860290650987, 0.035611875497567655, 0.03559925328215775, 0.03559887262194512, 0.035585261768002335, 0.035579988931203524, 0.0355673353494986, 0.035565909197923504, 0.035552995322369635, 0.03554723701190101, 0.03553597088144709, 0.03553247429147191, 0.03552127836087779, 0.03551412906904714, 0.0355047530073002, 0.03549900067050614, 0.035489703212264995, 0.03548108256046194, 0.03547341642163762, 0.03554234848771794, 0.03571580241816397, 0.035538685226445516, 0.035607428320617245, 0.035710117290386006, 0.03550787597983428, 0.03576095741988292, 0.03550983987403546, 0.035628035292465186, 0.035533292264172504, 0.03559837187253767, 0.0356017534910498, 0.035426691162748575, 0.03563805154742631, 0.03543391375389837, 0.03549691485763365, 0.03540851312751245, 0.03550572583681771, 0.03546203513518553, 0.03538540307886481, 0.035467414715257606, 0.035440109213559244, 0.035370244804278424, 0.03544103955998692, 0.035405137813381365, 0.0353414421207654, 0.03542494419377342, 0.0353691820876289, 0.03532522371852776, 0.03538443242518196, 0.035341416730056315, 0.035317354536046744, 0.03535693266355439, 0.035303108186614765, 0.035294656628017534, 0.03534071031281093, 0.03526987578759766, 0.03527862361166507, 0.03530517128965308, 0.03525601633146427, 0.03524933970883371, 0.035280761660402, 0.035232471280834565, 0.03522753913361819, 0.03525731977377648, 0.035203075376216086, 0.03520673689222777, 0.03523301115487599, 0.03536889270254313, 0.035456515588281785, 0.03523642537815871, 0.035608421342548394, 0.0356194582793768, 0.03531653550200359, 0.03570066153313756, 0.036076670749974386, 0.03608830190979176, 0.03569993273002508, 0.03547368648671295, 0.0357883575646208, 0.035510013669966374, 0.03597889429208562, 0.035641784861766904, 0.03546933780024992, 0.035294839825867605, 0.035249311874770935, 0.03515503130831832, 0.035149058712604014, 0.03508407548218117, 0.035053447204964144, 0.03501351061488784, 0.03497852582603517, 0.03495694795550662, 0.03492669927885142, 0.03487705790421662, 0.03486498131286984, 0.03484297593986285, 0.03483769498982857, 0.034807474328645005, 0.03480606157597378, 0.03479297095502285, 0.034781583005429315, 0.03477369282447974, 0.03476624525746605, 0.03475238464115457, 0.034749914827537726, 0.03473978428727114, 0.03473004300267042, 0.03472481419761662, 0.03471748044964743, 0.03470517325187762, 0.03470378142808159, 0.034694051102723444, 0.034684688308929165, 0.034681332790967655, 0.03467292726671285, 0.0346616517222114, 0.034661367588089825, 0.034650796628439826, 0.03464246178166711, 0.034640960127841014, 0.03463051729972803, 0.03462205765405048, 0.03462161116020472, 0.03460852092909723, 0.034603989360510026, 0.0346038998752963, 0.03458918848046781, 0.034585287624981594, 0.03458651526599581, 0.03456817058493217, 0.03456048748080396, 0.034559730714484795, 0.03454449670671762, 0.0345413095395456, 0.03454042905530093, 0.03452494248136694, 0.034518637436076006, 0.03451567417367406, 0.03450173552844752, 0.03450100377815058, 0.03449212180851322, 0.034480867885559596, 0.034477683600577944, 0.034472116526923675, 0.034458543789943945, 0.03445155573768117, 0.03444693485516759, 0.03443546030120872, 0.03443559770519867, 0.034424318715950156, 0.03441427204851653, 0.03441102712334876, 0.03440431124774706, 0.0343939916058555, 0.03438736465277117, 0.03438025562758828, 0.03437045696706861, 0.034369860104770875, 0.03435900763801695, 0.03435319023553078, 0.034346204566305084, 0.03433895886701311, 0.034334190415682475, 0.03432530467478868, 0.034317549047288176, 0.034312366795011616, 0.034304898402144804, 0.03429757605221388, 0.03429273925991826, 0.034283906274818435, 0.03427629725418603, 0.03427107955274478, 0.03426489115919457, 0.03425625838566481, 0.03425117857361506, 0.03424367212553714, 0.034235825229582656, 0.03423228005651733, 0.03422225450062009, 0.03421460132147929, 0.03420999940137824, 0.0342033939082375, 0.03419467515204306, 0.03419114203406181, 0.03418181666929906, 0.034174147539964804, 0.03417098717354372, 0.03416109068653041, 0.034152982257404554, 0.03414928429077862, 0.03414255799734212, 0.03413341459384532, 0.03413018845143875, 0.03412095327033811, 0.03411289466628916, 0.03411106175588399, 0.034100273035042414, 0.03409194456312583, 0.0340885630904692, 0.03408193141015879, 0.0340725179314856, 0.03407074801991356, 0.03406030703473387, 0.034052071769227484, 0.03405044489484929, 0.03404021982805294, 0.034031507131190936, 0.03402992154833224, 0.034020928901208516, 0.03401203012840503, 0.03401133863338581, 0.03399970579474098, 0.03399110953671338, 0.03398882007416935, 0.03398172193215712, 0.03397184556965055, 0.03397214258095206, 0.033960507836782346, 0.03395194191034779, 0.033958827391511695, 0.033948759418876026, 0.03394330007916698, 0.033931088437619404, 0.03393117299219945, 0.03391814398372373, 0.033910581023060125, 0.0339059068138973, 0.03389817797798061, 0.03388547707582727, 0.03388817297046963, 0.03387685090446632, 0.03387101750209529, 0.03386551572858373, 0.03385781880470733, 0.03384555992840385, 0.033849327908151684, 0.033836722152566015, 0.03383342476748156, 0.03382828080135507, 0.03381706756846521, 0.03380781872076215, 0.03381366091145043, 0.033795434522395, 0.033788288133997736, 0.03378717510041097, 0.033773298602893236, 0.03377315832178147, 0.03376869092892092, 0.0337559245738928, 0.03375062718040559, 0.033748315250629546, 0.03373731388983111, 0.03373003184645313, 0.033734314048093045, 0.033722697837576185, 0.03372617066636274, 0.033706235182333295, 0.033721083742840566, 0.03370172140453859, 0.033687124908188266, 0.033688582561814624, 0.03368561929191629, 0.03372117175751285, 0.033733598548528795, 0.033882088572019416, 0.033927082770944535, 0.033935394685645166, 0.034041803135544106, 0.03385436574937941, 0.0342046539602603, 0.03389377859830962, 0.033883398119234506, 0.033848065549503085, 0.03385208175030571, 0.033867019829230086, 0.033780336906155756, 0.033871840489241536, 0.03374532315585329, 0.03382301874847872, 0.03369464454624906, 0.033831459883574555, 0.033663161609630496, 0.03377918914922291, 0.033628038040897826, 0.03379250969301952, 0.033631356632947626, 0.033736422116643905, 0.033643232023706414, 0.03372949598906678, 0.03369954848892716, 0.03360708679334061, 0.03375068508177153, 0.03361042319566039, 0.033670043531707716, 0.03355536272185443, 0.03370754864139132, 0.033567304740112394, 0.033612417697330595, 0.03354217857814749, 0.03362027673092085, 0.03356938864855429, 0.03352682439801915, 0.0335757152054176, 0.03356766714128719, 0.03350711322547291, 0.03356859057363371, 0.033532748193439564, 0.033480433870897955, 0.03354950568970093, 0.033515543691793714, 0.03346567597329391, 0.03352021191273471, 0.033492560276526216, 0.033452238668637585, 0.033499614234387076, 0.03347084647832403, 0.0334233900760028, 0.03349312246963245, 0.033434486345303695, 0.03341574416066743, 0.033440129071648374, 0.03342442505830623, 0.03340345113724005, 0.03342210159712833, 0.03339493042022304, 0.0333800038759193, 0.03341281853231682, 0.03336299990818036, 0.03336967206834031, 0.03339233771117535, 0.03334575600088592, 0.03335341572583296, 0.033361696927560865, 0.03332248990323733, 0.03333575574903745, 0.033345712191495354, 0.033302598357917546, 0.03331824026888102, 0.03332508440433993, 0.03327992110618104, 0.03330253949897189, 0.033307885026019016, 0.033254927021778125, 0.03329327523937811, 0.033283684306025796, 0.03323716641576101, 0.033286144383816066, 0.03325672252437599, 0.033202161565354125, 0.03327467049347276, 0.03322755065974907, 0.03319744691175329, 0.03321971364646425, 0.033223285296053784, 0.03318110627950956, 0.033204913940941966, 0.033198956480854254, 0.033153911336623536, 0.03319902130096452, 0.0331756034154614, 0.03321989983610062, 0.03334537308190268, 0.03331890898583348, 0.033355966425512945, 0.033537979912011975, 0.03330283762455766, 0.03363063599831305, 0.03330486257164393, 0.03344564041008175, 0.03330709567199266, 0.033541492397481984, 0.033411941064988376, 0.03363146196885594, 0.033637037018777786, 0.0335412583125167, 0.03389304947354744, 0.03342247020163507, 0.03402936923423687, 0.033441951698081944, 0.03362069802314546, 0.0332515571850481, 0.03356795896244284, 0.03313305218237941, 0.03356306029896061, 0.03322369101203635, 0.03324898817561728, 0.033159710562591864, 0.03326863567712611, 0.03319026423886892, 0.0332056267750886, 0.033287936992597654, 0.033126612644244276, 0.03336476842843635, 0.033065562545726915, 0.0333947076837766, 0.03305622818433022, 0.03338241372472386, 0.03308841107909722, 0.033261230352015676, 0.033142598732900944, 0.033245830779328266, 0.03320695674318417, 0.033281391516664, 0.033407303121699414, 0.033140436419916965, 0.033617142398894434, 0.033089501175082, 0.033617922613354646, 0.03308064733760266, 0.033311794377258244, 0.03306744467958854, 0.03339616759704661, 0.033054821265711645, 0.0334574907539196, 0.033216397922508106, 0.03336151984328266, 0.03337711834789102, 0.03331999802098, 0.0336454609540488, 0.03317681136062194, 0.03382900477428448, 0.03319841180656588, 0.0334502326232155, 0.033050877372065496, 0.033368562433321695, 0.03295905262416319, 0.033380080373586654, 0.033032430060641535, 0.03310863669556611, 0.032989389937746416, 0.03313162403885693, 0.0330558091695486, 0.033060243407695686, 0.033187832466290056, 0.03298985637716265, 0.03329532180444441, 0.03289803465881744, 0.03342255292251196, 0.032963864398522, 0.0331531710587078, 0.03291389817662129, 0.03305456649398966, 0.032852285847168664, 0.033116867538067, 0.03296494900954916, 0.03318888606112287, 0.03317717516733852, 0.03327195583708588, 0.03349412193784223, 0.03320520519421532, 0.033844524162680564, 0.033195761690731435, 0.03383468183762682, 0.03360739696635047, 0.032840140619952975, 0.0328711775193412, 0.03268975312165385, 0.03274023100031059, 0.032583585954825, 0.032656396294475656, 0.032567721321561334, 0.03265336849980292, 0.032581527444720614, 0.03269992018233005, 0.032755656758045266, 0.03293064491809232, 0.03301113642848363, 0.03310873330338175, 0.03320383172087461, 0.03324438092253253, 0.03318537341906221, 0.03316697782189661, 0.03322348182197447, 0.03282317478923745, 0.03289261781210055, 0.0329164083268952, 0.032910277092723615, 0.03279984213046312, 0.032861643820200494, 0.03254380655897041, 0.032617607670104604, 0.03258511123133036, 0.03254395629062707, 0.032428503759061915, 0.032502403685262055, 0.032310899189980424, 0.03239478413818618, 0.032382373356177656, 0.03242720574641553, 0.03248256930346955, 0.0326470196382659, 0.03268207505752455, 0.032765238025872605, 0.032812831830052555, 0.03287732909603399, 0.0328275203916455, 0.03284129304820345, 0.032937013410592623, 0.032473429919938956, 0.03250558716236332, 0.03254134024405804, 0.03256121990434212, 0.03259810923709437, 0.03263620875383997, 0.032269294896729514, 0.032312770273974445, 0.032344605800328136, 0.03239834113811153, 0.03216646483764307, 0.03224668479962154, 0.03226952913052076, 0.0323566796759423, 0.03238690294360914, 0.03256939660626141, 0.03260199717946163, 0.03270378869507731, 0.03276860715939839, 0.03285191130492999, 0.03286296406870047, 0.03281305800837389, 0.032946891554115225, 0.0325080038012338, 0.0325854557064868, 0.032620862879217324, 0.032630235828485434, 0.03248952676178489, 0.03260651359109564, 0.032259003477647125, 0.032340747036344174, 0.03229729416614863, 0.032316806495027994, 0.03217744863380915, 0.032276450208579006, 0.03203099929866611, 0.03209028469777684, 0.032076583820539295, 0.032152762527939194, 0.03218025451475295, 0.03233939766926997, 0.03231223827334414, 0.03240826186251286, 0.0324734921616784, 0.03258992890164748, 0.03260153277853858, 0.03272463577201987, 0.03285825910631594, 0.032406999091298426, 0.032502063338028006, 0.03256345247689987, 0.03264122003369262, 0.03226973477268804, 0.03237867707419532, 0.032328180150625496, 0.0324280833502172, 0.0320756945771003, 0.03216293905268153, 0.032130379817143284, 0.032215887522682445, 0.03196175068000153, 0.03205663538386315, 0.031934188525286775, 0.03199459737469754, 0.03198649658165215, 0.032123692294343725, 0.031975535802396496, 0.03204111377006501, 0.032063584663569254, 0.03213395805822815, 0.03216955006765582, 0.03222140475755439, 0.0322932971540457, 0.03205677669208689, 0.03217340974826515, 0.031926375855981765, 0.03200081393298011, 0.03192131450893599, 0.03200610078730997, 0.03181845458544859, 0.03192042250985546, 0.031783143128011795, 0.031851913935307084, 0.03186588121691604, 0.03199106679117576, 0.032039826369125, 0.032202733137822244, 0.032293972215681255, 0.03243003374163799, 0.03250658831806514, 0.03267107454799447, 0.03257474846377407, 0.03323253424993012, 0.032713959216249165, 0.033151614563212264, 0.03254282901239689, 0.0329852124663758, 0.03248116241825669, 0.032893464797673196, 0.03242612833950857, 0.03292332941563546, 0.03236409388662026, 0.03273641883614039, 0.03233786237495587, 0.03271905667449684, 0.03226729004644151, 0.032747439488245114, 0.03226436877109215, 0.03248888465794454, 0.03217568830739352, 0.032584045034331266, 0.03211357892184355, 0.03245611484078417, 0.03210497110535814, 0.032226583811616756, 0.031943527956383874, 0.032414541771022286, 0.031947439431443375, 0.03206035464781186, 0.031831329604777504, 0.032074890524268505, 0.03181401306667762, 0.03193101665997229, 0.0317546241477462, 0.031990471406510984, 0.031798849387832444, 0.03203854092710836, 0.03202306529091653, 0.0321527405423011, 0.03231896520567193, 0.03218770691349162, 0.032746147774604654, 0.032270441536871725, 0.03283289465152786, 0.03250024545552103, 0.032418496583437116, 0.03229723764751091, 0.03294014716514544, 0.03249735398922394, 0.03279307583528838, 0.03256576020437666, 0.03280508938721699, 0.03257499921003116, 0.03305953037590702, 0.03271631866379013, 0.03310828045246006, 0.03283797387709131, 0.03314634708055335, 0.03259273425448405, 0.03319513397361961, 0.03282449949904749, 0.03309648295647206, 0.03266155848873892, 0.033140616448320004, 0.03280729950655921, 0.03319703746428325, 0.032686356427034685, 0.03307735989514852, 0.032706354618405244, 0.033254156560908785, 0.032792504155137105, 0.03311562539804143, 0.03266906943415802, 0.03314782706649758, 0.03270812720410538, 0.03323212196142158, 0.032794985301007974, 0.0331078174604241, 0.0326477391611795, 0.0331893828695829, 0.032734198347386834, 0.033202509815633836, 0.03275048636310423, 0.033098656094532705, 0.03262440936258073, 0.033224383635315546, 0.03279719809254187, 0.03318140849116526, 0.03264699249501925, 0.033081754512049644, 0.03268887935867995, 0.03325833683914949, 0.032754125199912436, 0.03310606283362938, 0.032652603933771576, 0.033164230526037695, 0.032655743939278205, 0.033214415206553875, 0.03278623890209325, 0.03313302853520759, 0.032605345241340955, 0.03316314406461478, 0.03270593595375593, 0.0332289932870125, 0.03273269961056372, 0.033091492104399496, 0.032597291518102776, 0.03322704125654692, 0.032756855764079, 0.033194235221786716, 0.03264851586047977, 0.033084119902191206, 0.03263174984397961, 0.03325937628571832, 0.03275684936107249, 0.03314697671027642, 0.03260569981974319, 0.03314271807931996, 0.03267751689903188, 0.03324126084802828, 0.03270933218933687, 0.03311638242074994, 0.03261625942499025, 0.033219284183703866, 0.03268606586177723, 0.03319841563117893, 0.032689637184196395, 0.03313973388557244, 0.03259744967425531, 0.033246011955787004, 0.03275447244136931, 0.03320086444433099, 0.03259833238888696, 0.03312942023809833, 0.032662736343733394, 0.033312188226685704, 0.03274496045740257, 0.03313788926145976, 0.03261042142241601, 0.03324780005235905, 0.03267453782409172, 0.0332439111060525, 0.03272924070425625, 0.03318011447262306, 0.032578686498457514, 0.03326593538244376, 0.0327733666884641, 0.03328097829936328, 0.032626866920343334, 0.033140059333590224, 0.032662723074817844, 0.033355410769564435, 0.032748711956675, 0.03320771648940623, 0.03263327690880213, 0.033260738010322796, 0.0326818286888758, 0.03332193028191906, 0.03275717816492681, 0.03324079439762771, 0.03262754539182895, 0.033297640217361556, 0.032727590626995484, 0.03332055898328829, 0.03271139666006684, 0.03322595940796366, 0.032626774550999584, 0.0333624523927941, 0.032799399738512355, 0.03330469851544572, 0.032607072390273766, 0.033235768822824675, 0.03275324564291332, 0.033424948683770835, 0.03272240562751327, 0.03321940552445285, 0.032678753584434055, 0.03340474981407565, 0.032722782778358675, 0.033298218156936385, 0.03272456033657417, 0.033311287905642084, 0.032628470628364124, 0.033384702675629915, 0.0328553424898782, 0.033373974364537054, 0.03259704226077659, 0.033285901519489125, 0.03282061009682615, 0.033476220577601024, 0.032689608997392705, 0.03323732017721764, 0.03270402869913132, 0.03349488036407618, 0.03280507860996986, 0.03333479611661651, 0.03266011162608119, 0.03336849413640546, 0.032784653051286666, 0.03346339071956665, 0.03275267017661375, 0.03333393983790575, 0.03270861171229124, 0.03347883864359562, 0.03280250824793081, 0.03339934761009238, 0.0327081475414588, 0.03338481364608899, 0.03273489524300868, 0.03350907244505946, 0.03286323329078477, 0.03342004548591148, 0.03267325672936089, 0.033419349651398575, 0.032828086972613656, 0.033554153056321194, 0.03280396100630894, 0.033378006552028466, 0.03271628394154348, 0.03354779768003536, 0.03288547359926652, 0.03349136926853585, 0.032697246231954816, 0.03341237106634239, 0.03286951018780803, 0.03361230125187447, 0.032784758583018145, 0.03341581506706596, 0.032794723450857766, 0.03360118806674352, 0.032839992876004864, 0.03351791502167899, 0.03282327935142655, 0.03352859310786916, 0.03277666125633688, 0.033616046062368045, 0.032957196726696045, 0.033572199173776386, 0.03272225121729981, 0.033521215280891394, 0.03295440554332925, 0.033723527597196004, 0.032842252862037374, 0.03346450392242196, 0.03283219416271716, 0.033736447783871096, 0.03295909094292553, 0.03360244294638946, 0.03279612209180763, 0.033580254847509323, 0.03296431375540769, 0.0337589201900802, 0.032884976401527155, 0.033552822501141326, 0.03287304858902536, 0.033766152957088874, 0.032987879436688676, 0.03367971468781049, 0.03286060116421927, 0.03364288926348488, 0.032953338052935106, 0.03380346440716914, 0.032982864600647414, 0.03366380126355406, 0.03289164064888002, 0.033738873486916524, 0.03300020215405329, 0.03381385173111619, 0.0329924876954023, 0.03368999706679334, 0.0329006911098865, 0.033803596079791096, 0.03310799810283261, 0.03383573375167418, 0.032869583475702194, 0.033671999103907974, 0.03310867879252599, 0.0339764230069538, 0.03297351810588229, 0.03366967719371581, 0.033008603027002634, 0.033949543001067374, 0.033095672202592304, 0.03383879532522039, 0.03299104570826515, 0.03381251660751533, 0.033070745376445325, 0.0339623279616742, 0.03309891872131995, 0.03384117300506426, 0.03302971126255274, 0.03390870853802773, 0.03312037519070457, 0.033972908468235204, 0.033110930513941726, 0.03387611142733, 0.033045922241067456, 0.03397601364926784, 0.033221362001817925, 0.03402054324689452, 0.033040783178543094, 0.03386440250751216, 0.03318845428261202, 0.03413093361139883, 0.033174147663020605, 0.033913245286702066, 0.03313515249516151, 0.03404686308819965, 0.033193134352118236, 0.03406125402642871, 0.03321731318282238, 0.03401443377883987, 0.03311934051777573, 0.03406362237081417, 0.0333289608659124, 0.034163048563483664, 0.033118813313258826, 0.033956049566319035, 0.03330218934385057, 0.03426413122409433, 0.03324140411127354, 0.03400937269277631, 0.03324383932703281, 0.03419304872386554, 0.033289558771933396, 0.034160317352754446, 0.03330745937681954, 0.034145822000449924, 0.03322464731761756, 0.034178518370775804, 0.033431813914221814, 0.034279797132150035, 0.03320289285806004, 0.0340717635454035, 0.033421778818900814, 0.03439485658614751, 0.03333282744693059, 0.0341065681695492, 0.033341021571019265, 0.03431360779033064, 0.03341529749360168, 0.03427713307874077, 0.03335617986882533, 0.03422220442810022, 0.03336167201675691, 0.03434822195947552, 0.03350426167642497, 0.0343336405215611, 0.03333868008341009, 0.03423395832107757, 0.0334764271991593, 0.03445233076098657, 0.03347747233325668, 0.03427062642276537, 0.03340349284615886, 0.034362152493655575, 0.0335220774044175, 0.03443027303258118, 0.0334785051678727, 0.03431813163456428, 0.03343450493335898, 0.03442295610399026, 0.03361771885860164, 0.03448970608599522, 0.03341597178252743, 0.034288527984552473, 0.033614349595797566, 0.034582277194748386, 0.03350986350013754, 0.034329093375667655, 0.03355010055382321, 0.034516259395389756, 0.03360781304185093, 0.034479054809918426, 0.033547796976066385, 0.03442764321639465, 0.03356135792794855, 0.03454287890229205, 0.033708653624679744, 0.03451837836487537, 0.033521785149793905, 0.034401381650545126, 0.03368430947438273, 0.034617960601847596, 0.033614465037614, 0.03442873794516724, 0.0335957340440207, 0.034553308799176216, 0.033734393083505426, 0.034597091196336714, 0.033591924392587236, 0.034432542731845435, 0.03370239242509169, 0.034649427609790534, 0.03369602358267524, 0.03449894470037575, 0.033665003678553324, 0.03456357110936377, 0.03370445930785919, 0.03458383949806452, 0.03374496784951774, 0.03456491580313455, 0.033661397018776566, 0.0345242927844877, 0.03377273162149957, 0.034644966903246296, 0.03371643357915782, 0.03450713992806643, 0.03369806018289994, 0.034598950227513914, 0.033833749824989795, 0.0346372222986831, 0.03366614100264532, 0.034472141213949134, 0.033805345312620375, 0.03469084625610886, 0.033780367928142735, 0.03451168789345291, 0.033730612913674365, 0.03456983558219702, 0.0338043674951317, 0.03461303221006898, 0.033780776850518314, 0.03453625288777013, 0.03371930239907358, 0.03455797447911495, 0.03389128753649893, 0.03465860807948532, 0.03368508160065943, 0.03443133039277633, 0.0338642748046627, 0.034687053262652354, 0.03378166785049136, 0.03446806140412508, 0.03377599875993015, 0.03456329176289765, 0.033835408912039684, 0.03457148167504286, 0.033785972300770045, 0.03449392321880265, 0.03375299998754597, 0.0345346154902207, 0.03391880476355945, 0.03459214996394887, 0.03368775772831779, 0.03437023510987514, 0.033898468454311666, 0.034624546477408064, 0.03374176594219655, 0.03438981400839613, 0.033781011866056844, 0.03451259153630183, 0.033884738309301485, 0.03451341460145909, 0.033688445347008884, 0.03434162454946619, 0.03388352153336806, 0.03456001360008337, 0.0337469016581243, 0.03433592409402923, 0.03376207087923662, 0.03443976694623648, 0.03386477262814869, 0.034452438152107474, 0.0336779118905893, 0.03427573681335718, 0.033846020833222766, 0.03447322363702052, 0.03374910781936742, 0.03427855174759029, 0.033724328981655, 0.0343299533891554, 0.03382327456539664, 0.03436604438832717, 0.033669331197543534, 0.03420773206905727, 0.03376524835910947, 0.034344348544803054, 0.03376240731779184, 0.03423778064965205, 0.033670170938387076, 0.03420065573171738, 0.03373637545667036, 0.034259389335626125, 0.03373708093278956, 0.0341777972314265, 0.033622421761824894, 0.034120814434305126, 0.03375081075402579, 0.03421428221441097, 0.033631058383214535, 0.03406584061215598, 0.03362877575685939, 0.03410957257612437, 0.03372233145417994, 0.0341350001260073, 0.033562503133883335, 0.03397726310674082, 0.033653958211501474, 0.03409586530740826, 0.03363403962439592, 0.033974666055116905, 0.03354843836573385, 0.0339455987942255, 0.03359083484791883, 0.033969743489891915, 0.033565377044912366, 0.033896912519830256, 0.03347361849185282, 0.033841255508799586, 0.033568286443116054, 0.03389432049535038, 0.03344908269856861, 0.03375602874798717, 0.03342844622000323, 0.03376976331872234, 0.033514375961520924, 0.033770564036352285, 0.03331558659633471, 0.03360511452409233, 0.033398913230422524, 0.0336799303346396, 0.033363332912532934, 0.033586548450764246, 0.03326124812851384, 0.03352493625274333, 0.033302716304217404, 0.033513675755261124, 0.033230879850666285, 0.033459199987117834, 0.033176961768313355, 0.03341132896890521, 0.03317952300104966, 0.03331468911327701, 0.03310254418497536, 0.03331379353467611, 0.033054598454903404, 0.03321278597414573, 0.03303156652429034, 0.03316652897055168, 0.032936286523248086, 0.033109025649287326, 0.03283993314902404, 0.032916779187302916, 0.03273213379292566, 0.032876195953011576, 0.03259228818253499, 0.0326894048083078, 0.03247034427342418, 0.032513759080447346, 0.032280023635524714, 0.0323901982314724, 0.032101010527231216, 0.03211588326735101, 0.031912840009990076, 0.031946301091605275, 0.03168297322424751, 0.03175429519838095, 0.03149121283201238, 0.03144133082924629, 0.03125375348505335, 0.03129711092561277, 0.03103825360101604, 0.031019575660235187, 0.030818863140360364, 0.030764496709276522, 0.03057679318650187, 0.030616481768379757, 0.030410850911053593, 0.030319570176485452, 0.030165788340580924, 0.030156346038781794, 0.02995374032376593, 0.029953308791799593, 0.029803330371589876, 0.02968550943004166, 0.029587531126799054, 0.02960786049751274, 0.02948179691491477, 0.029450612506342486, 0.02936652486977675, 0.0293367262603943, 0.029273909314368254, 0.029316195661900142, 0.029301315690225576, 0.029304179412071123, 0.029329022481129542, 0.029422595317396535, 0.02952004657180468, 0.02962170332073204, 0.029714457741114513, 0.029708605086447036, 0.02989397516494769, 0.029674403442335056, 0.030038412349441528, 0.029935067398404618, 0.029487077403855436, 0.02963913634460753, 0.029836022964279917, 0.02995090176741536, 0.03015909837725626, 0.030028332178063402, 0.03034603980845337, 0.03013935152319337, 0.029780100903154326, 0.02965030057463519, 0.03011623206492308, 0.030080420485502135, 0.02957529025788102, 0.02947165630526141, 0.02959622791151925, 0.029512986710754308, 0.029636493333815097, 0.029508349963526283, 0.029298475050548015, 0.02922512106996465, 0.02940155152661564, 0.029351823200789426, 0.029056002009598864, 0.02905653252695962, 0.029061851858877025, 0.02903967332336362, 0.029078507947602052, 0.029009364609797385, 0.029138512448494625, 0.029072843790010502, 0.029160902976884263, 0.02921113969513293, 0.02907851346098235, 0.029125766603084358, 0.029106892320777487, 0.029197413863471324, 0.029077403202838695, 0.02927285576814242, 0.0292088460547808, 0.029039080666126864, 0.029015067146822397, 0.029094107666727324, 0.02910411292881369, 0.02901362452284856, 0.0290646267628425, 0.029177505304565383, 0.029309247360436802, 0.029412398276182448, 0.029585520956852022, 0.029633077922966072, 0.029878241663399387, 0.029714434100391037, 0.0301445579972958, 0.030131474711041967, 0.029682727673599488, 0.02984129942762677, 0.03016325064531761, 0.030116634760505186, 0.03055606542555277, 0.030518361846116882, 0.03018554427484764, 0.030375269776233272, 0.030797230135185993, 0.030924328694158273, 0.031025118503892203, 0.03114477139743052, 0.03116846873047147, 0.03129778954551676, 0.031531612073714396, 0.03158314143232682, 0.03177156935645257, 0.03198615499060788, 0.0321785697539474, 0.032387241008619914, 0.0328209972938474, 0.03283415040411802, 0.03316528611309334, 0.03252891631385918, 0.0328111337063356, 0.03273323397235561, 0.03312818890419324, 0.03252821714072509, 0.03289821810024102, 0.03280246542751388, 0.033168544780716465, 0.03252290749203478, 0.03288328369263572, 0.03277286044039082, 0.03317828708300062, 0.03265394221360027, 0.032989810135233055, 0.03263600850334204, 0.03305763321992411, 0.03279572821272577, 0.03314384453141752, 0.03259865895535336, 0.03293810980448574, 0.03279859066206289, 0.033174473333727514, 0.03262375469011771, 0.03296274968658017, 0.032738343971454864, 0.03312175417302129, 0.03275997226129949, 0.03304535425590448, 0.03264367633844071, 0.03298015389616209, 0.032747395872949406, 0.03308596646068732, 0.032728923232297626, 0.03300301718016487, 0.03261627596719771, 0.03294653497418956, 0.0328058883848749, 0.03308529250904559, 0.03256652434143718, 0.03283979815240422, 0.03277294504159396, 0.03306979731041993, 0.03259384824409345, 0.032847529471779796, 0.032668251810085695, 0.0329659522463937, 0.03270104452012908, 0.032921830172206776, 0.03255992767983109, 0.0328083667454739, 0.03266847623958062, 0.0329156486911494, 0.03262880715837866, 0.0328085624116606, 0.032512014522478934, 0.03274135286624179, 0.03267391472646935, 0.032851689365210095, 0.032434872539119856, 0.03262076222226656, 0.03258452246283955, 0.03276843115731842, 0.03246663025811929, 0.032628811911310895, 0.03246997955008194, 0.03265572569490244, 0.032536739287533104, 0.03266867697048525, 0.032354355743819604, 0.03249399655724724, 0.032369203515247254, 0.03248968034491783, 0.032448823820235666, 0.03254994084255827, 0.032276537310266654, 0.03239023188114371, 0.03226397299883739, 0.03231667032992081, 0.03228526758882924, 0.032391460159346866, 0.03227512592916582, 0.03233390225294913, 0.032261808483400815, 0.032329340820849185, 0.03216177709943587, 0.032229403462759786, 0.032085734576648456, 0.032082554983347854, 0.03200889125512889, 0.03206015459314579, 0.03189666977491063, 0.03188530849669489, 0.03179668582390408, 0.031795932605340915, 0.03164353619079088, 0.031649313894626115, 0.03149248881143408, 0.031413853789253335, 0.03130946129298801, 0.03129639977716396, 0.031119488796584882, 0.031047202943861135, 0.030939155915904452, 0.030846630140619478, 0.030689761177809773, 0.030671422828681717, 0.030508549663507332, 0.030349384003868364, 0.030252451196792488, 0.030228893580919926, 0.03009275341843024, 0.029914232671679596, 0.029824934608807488, 0.02980131833379574, 0.029676253448421713, 0.029489296362668033, 0.029404550577729248, 0.029360822217382457, 0.029248416908086602, 0.029078521718205942, 0.029011517783580746, 0.028938800940842, 0.028849618929331352, 0.02874942138162319, 0.028697298587146588, 0.02858678069052327, 0.028543405874526633, 0.028515895240180774, 0.028499405646691935, 0.028426591208695305, 0.02843077316554709, 0.028445486637083874, 0.028494640803667204, 0.028515443504363712, 0.028604152077016377, 0.028697588872744574, 0.028824966632911085, 0.02896661784054008, 0.029138494427524253, 0.029109127194015504, 0.02929337897349466, 0.02913493593622101, 0.02921483495009609, 0.02929351664849247, 0.028886836753729425, 0.02907034155484172, 0.02934746528514028, 0.02943603188728144, 0.029648471092881407, 0.029547274948565794, 0.029716259373589023, 0.02972609225987399, 0.029348293253601755, 0.029425944552954636, 0.029661715822583784], \"yaxis\": \"y\"}],\n","                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Auto Encoder - 8 | Loss vs Epochs\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('e970a1b4-f8b1-4ca8-8c0b-6a79437690da');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"fPhhm-Ml6DoD","executionInfo":{"status":"ok","timestamp":1630506671392,"user_tz":180,"elapsed":4,"user":{"displayName":"Lucas Nunes Sequeira","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjbpJZX1cXPIHyQ8qs02ItTnmGeGQtbj7gk0GSegA=s64","userId":"06789563524461789788"}},"outputId":"805b5537-4a17-4d0e-8cff-9d1fd3acd467"},"source":["fig = px.line(y=hist_15['loss'])\n","fig.update_layout(\n","    title = 'Auto Encoder - 15 | Loss vs Epochs',\n","    xaxis_title = 'Epoch',\n","    yaxis_title = 'Loss'\n",")"],"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"35400a34-0154-4db4-9e40-dbf25025295a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"35400a34-0154-4db4-9e40-dbf25025295a\")) {\n","                    Plotly.newPlot(\n","                        '35400a34-0154-4db4-9e40-dbf25025295a',\n","                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"y=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"xaxis\": \"x\", \"y\": [0.966329370832908, 0.5140374942627941, 0.4878614963200901, 0.4707788127973651, 0.45396475684068643, 0.4432310786933347, 0.4285458742769342, 0.41669429436034766, 0.40689185898124786, 0.3980070144832924, 0.39099086166682573, 0.38330419789655634, 0.3759159884619482, 0.37011497103306246, 0.3651999845944668, 0.3607396906962389, 0.355715241064898, 0.35172710486766523, 0.3470024073728277, 0.34322276399778073, 0.33846768472811006, 0.3324446927872162, 0.3260640596700647, 0.32044927365886194, 0.3151431563940786, 0.30998929326332886, 0.30456030669256834, 0.3001485712558003, 0.2944924090031592, 0.29013266772913393, 0.2853253435770206, 0.2810491869320255, 0.2770050048596111, 0.2720594361734476, 0.2680057116117131, 0.2634176830699566, 0.25835944532071026, 0.2540760879915286, 0.2501722728921395, 0.24506765346988613, 0.2402616311649446, 0.23636694823113366, 0.23107976473116168, 0.22698843971506172, 0.2222417927588835, 0.21702724019359926, 0.21279138656923252, 0.2089874875476565, 0.20314146249299883, 0.19889058561304573, 0.19401294359746546, 0.18926272905896083, 0.1845295450075926, 0.17950602496613213, 0.17492490393976345, 0.17008044447740653, 0.16584082993738597, 0.16119660152595833, 0.15557048452042888, 0.1519628052101268, 0.1479846168510599, 0.1430931531450836, 0.1388349771950561, 0.13545789295990085, 0.13025694782264233, 0.1272295520156729, 0.1228444392892812, 0.11794635695769098, 0.11479809523514437, 0.11165488862323496, 0.108891765220479, 0.10485041086088302, 0.10089183958962591, 0.09817104473049731, 0.09540178284293892, 0.0925512321532078, 0.088525046726589, 0.08520283627077782, 0.08172974676947149, 0.07823407093717336, 0.07524594111133746, 0.07274972488635391, 0.0703339609644434, 0.0672125715174223, 0.06519912591715663, 0.06222482844272267, 0.05964058865079266, 0.056155703283414425, 0.05302804314294703, 0.050459477830203124, 0.048628237164703936, 0.04580278314446307, 0.04239182220313086, 0.039980208118737724, 0.03751668848064957, 0.03550279962975937, 0.03259538790325628, 0.030719661637621073, 0.028390714625249322, 0.026639605097489256, 0.024938695156741377, 0.02331959364104637, 0.02208088091639758, 0.020256189792894216, 0.019103957924531942, 0.017410012130790263, 0.016257979507582822, 0.015220256760234273, 0.014407650103303778, 0.013141079440089055, 0.012254488283123192, 0.011429236377440078, 0.010667771458785147, 0.010047820673339182, 0.009230337219055145, 0.008354061686837827, 0.007755660929618365, 0.007227065323550466, 0.006799950532228217, 0.006169781258683165, 0.00572636704163288, 0.005336693406187799, 0.004849164150103377, 0.0045501904144778504, 0.004108602199807888, 0.0038103992442583053, 0.00352488661392156, 0.0032751998933075238, 0.0030732359587168, 0.0027810112068212592, 0.0025247805912243836, 0.0023256742312483957, 0.002158997689211762, 0.002005983332360632, 0.0018541598441983915, 0.0017199073453089803, 0.0016150797770849066, 0.001448472532332074, 0.00131867106858643, 0.001207797774186414, 0.0011232190436913417, 0.0010394939649542466, 0.0009641382923742789], \"yaxis\": \"y\"}],\n","                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Auto Encoder - 15 | Loss vs Epochs\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('35400a34-0154-4db4-9e40-dbf25025295a');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{}}]}]}